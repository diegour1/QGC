{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7VwQfaCOcok"
      },
      "source": [
        "## Quantum Generative Classification with Mixed States on $28 \\times 28$ Binary (3, 6) MNIST\n",
        "\n",
        "Diego Useche Reyes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU"
      ],
      "metadata": {
        "id": "Px6NXiW6Q74M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al0mmMn7Q9oM",
        "outputId": "972f0399-0d79-4047-d82e-0871ec433763"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPeuojM4RUB1"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5IafHoCOqgN",
        "outputId": "09ecb290-b1ff-400f-8096-b607d926f4db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorcircuit\n",
            "  Downloading tensorcircuit-0.12.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorcircuit) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tensorcircuit) (1.13.1)\n",
            "Collecting tensornetwork-ng (from tensorcircuit)\n",
            "  Downloading tensornetwork_ng-0.5.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from tensorcircuit) (3.3)\n",
            "Requirement already satisfied: graphviz>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from tensornetwork-ng->tensorcircuit) (0.20.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from tensornetwork-ng->tensorcircuit) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensornetwork-ng->tensorcircuit) (3.11.0)\n",
            "Downloading tensorcircuit-0.12.0-py3-none-any.whl (342 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.0/342.0 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensornetwork_ng-0.5.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensornetwork-ng, tensorcircuit\n",
            "Successfully installed tensorcircuit-0.12.0 tensornetwork-ng-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorcircuit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "15DqVUX2Ocop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d819efb-b94c-4754-ccba-c1611469c2a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorcircuit.translation:Please first ``pip install -U qiskit`` to enable related functionality in translation module\n",
            "WARNING:tensorcircuit.translation:Please first ``pip install -U cirq`` to enable related functionality in translation module\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorcircuit as tc\n",
        "from tensorcircuit import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzQg29OoOcos",
        "outputId": "e393c4d8-5625-44ef-c311-b528c6a2707c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('complex128', 'float64')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "tc.set_backend(\"tensorflow\")\n",
        "tc.set_dtype(\"complex128\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P856730WaRBB",
        "outputId": "f4559f2c-eac4-45d0-adb1-2c49f3e0a3d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n",
            "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_logical_devices())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHUQ385IUKo4"
      },
      "source": [
        "## Utils functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcxPN_lIUNI0",
        "outputId": "004b7bea-0947-4fa4-f91d-677ce0df7174"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 4, 8, 12]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# this function takes the number of classes and of qubits of the qmc pure, and extract the indices\n",
        "# of the bit strings that correpond to the classes prediction\n",
        "## Example, qmc prediction bit string [\"00\", \"01\", \"10\", \"11\"]\n",
        "## the classes prediction is encoded in [\"00\", \"10\"], then it returns [0, 2]\n",
        "\n",
        "def _indices_qubits_classes(num_qubits_param, num_classes_param):\n",
        "  num_qubits_classes_temp = int(np.ceil(np.log2(num_classes_param)))\n",
        "  a = [np.binary_repr(i, num_qubits_param) for i in range(2**num_qubits_param)]\n",
        "  b = [(np.binary_repr(i, num_qubits_classes_temp) + \"0\"*(num_qubits_param - num_qubits_classes_temp)) for i in range(num_classes_param)]\n",
        "  indices_temp = []\n",
        "  for i in range(len(a)):\n",
        "    if a[i] in b:\n",
        "      indices_temp.append(i)\n",
        "\n",
        "  return indices_temp\n",
        "\n",
        "_indices_qubits_classes(4, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MNIST Dataset"
      ],
      "metadata": {
        "id": "VRK7Lqt_pVVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "\"\"\"\n",
        "Module for MNIST Digits Dataset preprocessing.\n",
        "https://www.tensorflow.org/quantum/tutorials/mnist\n",
        "\n",
        "Python 3.10.11\n",
        "\"\"\"\n",
        "\n",
        "def filter_by_classes(x, y, classes=[3,6]):\n",
        "    \"\"\"\n",
        "    Function that filters the MNIST Digits Dataset and returns samples on 'classes'.\n",
        "    Parameters:\n",
        "        x: Sample images.\n",
        "        y: Sample labels.\n",
        "        classes: List of classes to filter.\n",
        "    Returns:\n",
        "        x: x filtered by 'classes'.\n",
        "        y: x filtered by 'classes'.\n",
        "    \"\"\"\n",
        "    if not all(np.isin(classes, range(0, 10))):\n",
        "        return ValueError(\"Classes must be a list of digits (0-9).\")\n",
        "    x, y = x[np.isin(y, classes)], y[np.isin(y, classes)]\n",
        "    if len(classes)==2:\n",
        "        return x, y==classes[-1]\n",
        "    else:\n",
        "        return x, y\n",
        "\n",
        "def remove_contradicting(xs, ys):\n",
        "\n",
        "    mapping = collections.defaultdict(set)\n",
        "    orig_x = {}\n",
        "    # Determine the set of labels for each unique image:\n",
        "    for x,y in zip(xs,ys):\n",
        "       orig_x[tuple(x.flatten())] = x\n",
        "       mapping[tuple(x.flatten())].add(y)\n",
        "\n",
        "    new_x = []\n",
        "    new_y = []\n",
        "    for flatten_x in mapping:\n",
        "      x = orig_x[flatten_x]\n",
        "      labels = mapping[flatten_x]\n",
        "      if len(labels) == 1:\n",
        "          new_x.append(x)\n",
        "          new_y.append(next(iter(labels)))\n",
        "      else:\n",
        "          # Throw out images that match more than one label.\n",
        "          pass\n",
        "\n",
        "    num_uniq_3 = sum(1 for value in mapping.values() if len(value) == 1 and True in value)\n",
        "    num_uniq_6 = sum(1 for value in mapping.values() if len(value) == 1 and False in value)\n",
        "    num_uniq_both = sum(1 for value in mapping.values() if len(value) == 2)\n",
        "\n",
        "    print(\"Number of unique images:\", len(mapping.values()))\n",
        "    print(\"Number of unique 3s: \", num_uniq_3)\n",
        "    print(\"Number of unique 6s: \", num_uniq_6)\n",
        "    print(\"Number of unique contradicting labels (both 3 and 6): \", num_uniq_both)\n",
        "    print()\n",
        "    print(\"Initial number of images: \", len(xs))\n",
        "    print(\"Remaining non-contradicting unique images: \", len(new_x))\n",
        "\n",
        "    return np.array(new_x), np.array(new_y)\n",
        "\n",
        "def preprocess_mnist_digits(classes=[3,6]):\n",
        "    \"\"\"\"\n",
        "    Function that downloads the MNIST Digits dataset with TensorFlow and performs the following tasks:\n",
        "        1. Normalizes pixel values from (0, 255) to (0, 1).\n",
        "        2. By default, returns only 2 classes of digits for classification (this can be deactivated or modified by the 'classes' parameter).\n",
        "        3. Resizes samples to 4x4 images.\n",
        "        4. Removes samples that belong to multiple classes simultaneously.\n",
        "        5. Converts images to binary.\"\n",
        "    Parameters:\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "\n",
        "    # Download dataset\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    # Rescale the images from [0,255] to the [0.0,1.0] range.\n",
        "    x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
        "\n",
        "    # Filter to get only '3's and '6's\n",
        "    x_train, y_train = filter_by_classes(x_train, y_train, classes=classes)\n",
        "    x_test, y_test = filter_by_classes(x_test, y_test, classes=classes)\n",
        "\n",
        "    print(\"Number of filtered training examples:\", len(x_train))\n",
        "    print(\"Number of filtered test examples:\", len(x_test))\n",
        "\n",
        "    x_train_nocon, y_train_nocon = remove_contradicting(x_train, y_train)\n",
        "\n",
        "    THRESHOLD = 0.5\n",
        "\n",
        "    # Converts non contradicting samples to binary via threshold and converting bool to float.\n",
        "    x_train_bin = np.array(x_train_nocon > THRESHOLD, dtype=np.float32)\n",
        "    x_test_bin = np.array(x_test > THRESHOLD, dtype=np.float32)\n",
        "\n",
        "    return x_train_bin, y_train_nocon, x_test_bin, y_test\n",
        "\n",
        "X_train, y_train, X_test, y_test = preprocess_mnist_digits()\n",
        "X_train *= np.pi\n",
        "X_test *= np.pi\n",
        "y_train = np.where(y_train==False, 0, 1)\n",
        "y_test = np.where(y_test==False, 0, 1)\n",
        "y_train_oh = tf.reshape(tf.keras.backend.one_hot(y_train, 2), (-1,2))\n",
        "y_test_oh = tf.reshape(tf.keras.backend.one_hot(y_train, 2), (-1,2))\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape, y_train_oh.shape, y_test_oh.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntWxnOeg8PVy",
        "outputId": "a93a648c-7db9-4e96-a70d-9b94c10d9856"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Number of filtered training examples: 12049\n",
            "Number of filtered test examples: 1968\n",
            "Number of unique images: 12049\n",
            "Number of unique 3s:  5918\n",
            "Number of unique 6s:  6131\n",
            "Number of unique contradicting labels (both 3 and 6):  0\n",
            "\n",
            "Initial number of images:  12049\n",
            "Remaining non-contradicting unique images:  12049\n",
            "(12049, 28, 28, 1) (12049,) (1968, 28, 28, 1) (1968,) (12049, 2) (12049, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXgj4raiOK_a"
      },
      "source": [
        "## Model 1: Mixed QMC variational, QEFF, APA, generative with Le-Net Conv layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhHsdsdg75os"
      },
      "outputs": [],
      "source": [
        "### Quantum variational KDC with QEFF\n",
        "\n",
        "import tensorcircuit as tc\n",
        "from tensorcircuit import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import math as m\n",
        "from scipy.stats import entropy, spearmanr\n",
        "\n",
        "\n",
        "\n",
        "tc.set_backend(\"tensorflow\")\n",
        "tc.set_dtype(\"complex128\")\n",
        "\n",
        "pi = tf.constant(m.pi)\n",
        "\n",
        "\n",
        "class VQKDC_MIXED_QEFF_LENET:\n",
        "    r\"\"\"\n",
        "    Defines the ready-to-use Quantum measurement classification (QMC) model implemented\n",
        "    in TensorCircuit using the TensorFlow/Keras API. Any additional argument in the methods has to be Keras-compliant.\n",
        "\n",
        "    Args:\n",
        "        auto_compile: A boolean to autocompile the model using default settings. (Default True).\n",
        "        var_pure_state_size:\n",
        "        gamma:\n",
        "\n",
        "    Returns:\n",
        "        An instantiated model ready to train with ad-hoc data.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, n_qeff_qubits, n_ancilla_qubits, num_classes_qubits, num_classes_param, dim_lenet_out_param, input_dim_param, gamma, n_training_data,  reduction = \"none\", training_type = \"generative\", batch_size = 16, learning_rate = 0.0005, random_state = 15, auto_compile=True):\n",
        "\n",
        "        self.circuit = None\n",
        "        self.gamma = gamma\n",
        "        self.num_classes = num_classes_param\n",
        "        self.num_classes_qubits = num_classes_qubits\n",
        "        self.n_qeff_qubits = n_qeff_qubits\n",
        "        self.n_ancilla_qubits = n_ancilla_qubits\n",
        "        self.n_total_qubits_temp = self.num_classes_qubits + self.n_qeff_qubits + self.n_ancilla_qubits\n",
        "        self.num_ffs = 2**self.n_qeff_qubits\n",
        "        self.n_training_data = n_training_data\n",
        "        self.dim_lenet_out = dim_lenet_out_param\n",
        "        self.input_dim = input_dim_param\n",
        "        self.var_pure_state_parameters_size = 2*(2**self.n_total_qubits_temp - 1)\n",
        "        self.reduction  = reduction\n",
        "        self.training_type = training_type\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.qeff_weights = tf.random.normal((self.dim_lenet_out, int(self.num_ffs*1-1)), mean = 0.0, stddev = 2.0/np.sqrt(self.num_ffs - 1), dtype=tf.dtypes.float64, seed = random_state)\n",
        "\n",
        "        layer = keras.QuantumLayer(\n",
        "            partial(self.layer),\n",
        "            [(self.var_pure_state_parameters_size,)]\n",
        "            )\n",
        "\n",
        "        ## build the Let-net model\n",
        "        self.model = Sequential()\n",
        "        self.model.add(tf.keras.layers.Conv2D(filters=20, kernel_size=(5, 5), padding=\"same\", activation='relu', input_shape=(self.input_dim, self.input_dim, 1)))\n",
        "        self.model.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2))\n",
        "        self.model.add(tf.keras.layers.Conv2D(filters=50, kernel_size=(5, 5), padding=\"same\", activation='relu'))\n",
        "        self.model.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2))\n",
        "        self.model.add(tf.keras.layers.Flatten())\n",
        "        self.model.add(tf.keras.layers.Dense(units=84, activation='relu'))\n",
        "        self.model.add(tf.keras.layers.Dense(units=self.dim_lenet_out, activation = 'relu')) # original \"softmax\"\n",
        "\n",
        "        # add the quantum layer\n",
        "\n",
        "        self.model.add(layer)\n",
        "        print(self.model.summary())\n",
        "\n",
        "        if auto_compile:\n",
        "            self.compile()\n",
        "\n",
        "    def layer(\n",
        "            self,\n",
        "            x_sample_param,\n",
        "            var_pure_state_param,\n",
        "        ):\n",
        "        r\"\"\"\n",
        "        Defines a Density Matrix Kernel Density Estimation quantum layer for learning with fixed qaff (Meaning of qaff?). (This function was originally named dmkde_mixed_variational_density_estimation_fixed_qaff)\n",
        "\n",
        "        Args:\n",
        "            U_dagger:\n",
        "            var_pure_state_param:\n",
        "\n",
        "        Returns:\n",
        "            The probabilities of :math:`|k\\rangle`, `|1\\rangle`, ..., `|k\\rangle` state for kernel density classification of the classes.\n",
        "        \"\"\"\n",
        "\n",
        "        ### indices pure state\n",
        "        index_it = iter(np.arange(len(var_pure_state_param)))\n",
        "\n",
        "        ### indices qeff\n",
        "        index_iter_qeff = iter(np.arange(self.qeff_weights.shape[1]))\n",
        "\n",
        "        ### indices classes, of ms\n",
        "        n_qubits_classes_qeff_temp = self.num_classes_qubits + self.n_qeff_qubits\n",
        "        index_qubit_states = _indices_qubits_classes(n_qubits_classes_qeff_temp, self.num_classes) # extract indices of the bit string of classes\n",
        "\n",
        "\n",
        "        # Instantiate a circuit with the calculated number of qubits.\n",
        "        self.circuit = tc.Circuit(self.n_total_qubits_temp)\n",
        "\n",
        "        def circuit_base_ry_n(qc_param, num_qubits_param, target_qubit_param):\n",
        "            if num_qubits_param == 1:\n",
        "                qc_param.ry(0, theta = var_pure_state_param[next(index_it)])\n",
        "            elif num_qubits_param == 2:\n",
        "                qc_param.ry(target_qubit_param, theta=var_pure_state_param[next(index_it)])\n",
        "                qc_param.cnot(0, target_qubit_param)\n",
        "                qc_param.ry(target_qubit_param, theta=var_pure_state_param[next(index_it)])\n",
        "                return\n",
        "            else:\n",
        "                circuit_base_ry_n(qc_param, num_qubits_param-1, target_qubit_param)\n",
        "                qc_param.cnot(num_qubits_param-2, target_qubit_param)\n",
        "                circuit_base_ry_n(qc_param, num_qubits_param-1, target_qubit_param)\n",
        "                target_qubit_param -= 1\n",
        "\n",
        "        def circuit_base_rz_n(qc_param, num_qubits_param, target_qubit_param):\n",
        "            if num_qubits_param == 1:\n",
        "                qc_param.rz(0, theta = var_pure_state_param[next(index_it)])\n",
        "            elif num_qubits_param == 2:\n",
        "                qc_param.rz(target_qubit_param, theta=var_pure_state_param[next(index_it)])\n",
        "                qc_param.cnot(0, target_qubit_param)\n",
        "                qc_param.rz(target_qubit_param, theta=var_pure_state_param[next(index_it)])\n",
        "                return\n",
        "            else:\n",
        "                circuit_base_rz_n(qc_param, num_qubits_param-1, target_qubit_param)\n",
        "                qc_param.cnot(num_qubits_param-2, target_qubit_param)\n",
        "                circuit_base_rz_n(qc_param, num_qubits_param-1, target_qubit_param)\n",
        "                target_qubit_param -= 1\n",
        "\n",
        "        # Learning pure state\n",
        "        for i in range(1, self.n_total_qubits_temp+1):\n",
        "            circuit_base_ry_n(self.circuit, i, i-1)\n",
        "\n",
        "        # Learning pure state complex phase\n",
        "        for j in range(1, self.n_total_qubits_temp+1):\n",
        "            circuit_base_rz_n(self.circuit, j, j-1)\n",
        "\n",
        "        # Value to predict\n",
        "\n",
        "        x_sample_temp = tf.expand_dims(x_sample_param, axis=0)\n",
        "        phases_temp = (tf.cast(tf.sqrt(self.gamma), tf.float64)*tf.linalg.matmul(tf.cast(x_sample_temp, tf.float64), self.qeff_weights))[0]\n",
        "        init_qubit_qeff_temp = self.num_classes_qubits # qubit at which the qaff mapping starts it starts after the qubits of the classes\n",
        "\n",
        "        def circuit_base_rz_qeff_n(qc_param, num_qubits_param, target_qubit_param, init_qubit_param):\n",
        "          if num_qubits_param == 1:\n",
        "            qc_param.rz(init_qubit_param, theta = phases_temp[next(index_iter_qeff)] )\n",
        "          elif num_qubits_param == 2:\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[next(index_iter_qeff)])\n",
        "            qc_param.cnot(init_qubit_param, target_qubit_param + init_qubit_param)\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[next(index_iter_qeff)])\n",
        "            return\n",
        "          else:\n",
        "            circuit_base_rz_qeff_n(qc_param, num_qubits_param-1, target_qubit_param, init_qubit_param)\n",
        "            qc_param.cnot(num_qubits_param-2 + init_qubit_param, target_qubit_param + init_qubit_param)\n",
        "            circuit_base_rz_qeff_n(qc_param, num_qubits_param-1, target_qubit_param, init_qubit_param)\n",
        "            target_qubit_param -= 1\n",
        "\n",
        "        # Applying the QEFF feature map\n",
        "\n",
        "        for i in reversed(range(1, self.n_qeff_qubits + 1)):\n",
        "          circuit_base_rz_qeff_n(self.circuit, i, i - 1, init_qubit_qeff_temp)\n",
        "\n",
        "        for i in range(init_qubit_qeff_temp, init_qubit_qeff_temp + self.n_qeff_qubits):\n",
        "          self.circuit.H(i)\n",
        "\n",
        "        # Trace out ancilla qubits, find probability of [000] state for density estimation\n",
        "        measurement_state = tc.quantum.reduced_density_matrix(\n",
        "                        self.circuit.state(),\n",
        "                        cut=[m for m in range(n_qubits_classes_qeff_temp, self.n_total_qubits_temp)])\n",
        "        measurements_results = tc.backend.real(tf.stack([measurement_state[index_qubit_states[i], index_qubit_states[i]] for i in range(self.num_classes)]))\n",
        "        if self.training_type == \"discriminative\":\n",
        "          measurements_results = measurements_results / tf.reduce_sum(measurements_results, axis = -1)\n",
        "        return measurements_results\n",
        "\n",
        "    def custom_categorical_crossentropy(self, y_true, y_pred):\n",
        "      ## code generated with the aid of chat gpt\n",
        "      \"\"\"\n",
        "      Compute the categorical cross-entropy loss with mean reduction.\n",
        "\n",
        "      Args:\n",
        "      y_true: Tensor of true labels, shape (batch_size, num_classes).\n",
        "      y_pred: Tensor of predicted probabilities, shape (batch_size, num_classes).\n",
        "\n",
        "      Returns:\n",
        "      Scalar tensor representing the mean loss over the batch.\n",
        "      \"\"\"\n",
        "      # Ensure predictions are clipped to avoid log(0)\n",
        "      epsilon_two = 1e-7  # small constant to avoid division by zero\n",
        "      y_pred = tf.clip_by_value(y_pred, epsilon_two, np.inf)  # clip values to avoid log(0) originaly 1.0 - epsilon\n",
        "\n",
        "      # Compute the categorical cross-entropy loss for each sample\n",
        "      loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
        "\n",
        "      if self.reduction == \"none\":\n",
        "        return loss\n",
        "      elif self.reduction == \"mean\":\n",
        "        # Compute the mean loss over the batch\n",
        "        mean_loss = tf.reduce_mean(loss)\n",
        "        return mean_loss\n",
        "      elif self.reduction == \"sum\":\n",
        "        # Compute the sum loss over the batch\n",
        "        sum_loss = tf.reduce_sum(loss)\n",
        "        return sum_loss\n",
        "      else:\n",
        "        return loss\n",
        "\n",
        "    def compile(\n",
        "            self,\n",
        "            optimizer=tf.keras.optimizers.Adam,\n",
        "            **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to compile the model.\n",
        "\n",
        "        Args:\n",
        "            optimizer:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "        self.model.compile(\n",
        "            loss = self.custom_categorical_crossentropy,\n",
        "            optimizer=optimizer(self.learning_rate),\n",
        "            metrics=[\"accuracy\"],\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "    def fit(self, x_train, y_train, batch_size=16, epochs = 30, **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to fit (train) the model using the ad-hoc dataset.\n",
        "\n",
        "        Args:\n",
        "            x_train:\n",
        "            y_train:\n",
        "            batch_size:\n",
        "            epochs:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model.fit(x_train, y_train, batch_size = self.batch_size, epochs = epochs, **kwargs)\n",
        "\n",
        "    def predict(self, x_test):\n",
        "      r\"\"\"\n",
        "      Method to make predictions with the trained model.\n",
        "\n",
        "      Args:\n",
        "          x_test:\n",
        "\n",
        "      Returns:\n",
        "          The predictions of the conditional density estimation of the input data.\n",
        "      \"\"\"\n",
        "      return (tf.experimental.numpy.power((self.gamma/(pi)), self.dim_lenet_out/2.)*\\\n",
        "          self.model.predict(x_test)).numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPwT6lreFL0H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02b4f4df-5b83-4264-82df-375566c07626"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 4, 1, 1.0, 123, 123, 0.0005, 12049, 'none', 'generative')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Define a LeNet CNN feature extraction model\n",
        "input_shape = X_train.shape[1:]\n",
        "INPUT_DIM = input_shape[0]\n",
        "NUM_QUBITS_FFS = 4 ## originally N_QEFFS = 16\n",
        "NUM_CLASSES = 2\n",
        "NUM_CLASSES_QUBITS = 1\n",
        "DIM_LENET_OUT = 14 # originally 16\n",
        "GAMMA = 1.0 ## originally 2**(0)\n",
        "EPOCHS = 8\n",
        "N_TRAINING_DATA = X_train.shape[0]\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.0005 ## originally 0.0005\n",
        "RANDOM_STATE_QEFF = 123\n",
        "NUM_ANCILLA_QUBITS = 1\n",
        "REDUCTION = \"none\"\n",
        "TRAINING_TYPE = \"generative\"\n",
        "\n",
        "EPOCHS, NUM_QUBITS_FFS, NUM_ANCILLA_QUBITS, GAMMA, RANDOM_STATE_QEFF, RANDOM_STATE_QEFF, LEARNING_RATE, N_TRAINING_DATA, REDUCTION, TRAINING_TYPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oi9qNE3R75ot",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "outputId": "0f7d5bdc-cf1d-4ef8-d404-b1a97a7ddb3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │             \u001b[38;5;34m520\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d (\u001b[38;5;33mAveragePooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │          \u001b[38;5;34m25,050\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_1                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2450\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)                  │         \u001b[38;5;34m205,884\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │           \u001b[38;5;34m1,190\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ quantum_layer (\u001b[38;5;33mQuantumLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m126\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,050</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_1                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2450</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">205,884</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,190</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ quantum_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">QuantumLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m232,770\u001b[0m (909.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">232,770</span> (909.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m232,770\u001b[0m (909.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">232,770</span> (909.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 73ms/step - accuracy: 0.5119 - loss: 4.9141\n",
            "Epoch 2/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 73ms/step - accuracy: 0.5162 - loss: 3.1851\n",
            "Epoch 3/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 73ms/step - accuracy: 0.5131 - loss: 2.4564\n",
            "Epoch 4/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 74ms/step - accuracy: 0.5075 - loss: 2.0231\n",
            "Epoch 5/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 74ms/step - accuracy: 0.5085 - loss: 1.6639\n",
            "Epoch 6/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 72ms/step - accuracy: 0.5041 - loss: 1.3953\n",
            "Epoch 7/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 118ms/step - accuracy: 0.5156 - loss: 1.1684\n",
            "Epoch 8/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 85ms/step - accuracy: 0.5117 - loss: 1.0294\n"
          ]
        }
      ],
      "source": [
        "## training the quantum circuit\n",
        "vqkdc_lenet = VQKDC_MIXED_QEFF_LENET(n_qeff_qubits = NUM_QUBITS_FFS, n_ancilla_qubits =  NUM_ANCILLA_QUBITS, num_classes_qubits = NUM_CLASSES_QUBITS, num_classes_param = NUM_CLASSES, dim_lenet_out_param = DIM_LENET_OUT, input_dim_param = INPUT_DIM, n_training_data = N_TRAINING_DATA, reduction = REDUCTION, training_type = TRAINING_TYPE, gamma=GAMMA, batch_size = BATCH_SIZE, learning_rate = LEARNING_RATE, random_state = RANDOM_STATE_QEFF)\n",
        "\n",
        "vqkdc_lenet.fit(X_train, y_train_oh, epochs = EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vqkdc_lenet.fit(X_train, y_train_oh, epochs = EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFVzAhF0mRXT",
        "outputId": "160001de-b78d-4e7d-a637-d76411d6d983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 72ms/step - accuracy: 0.5131 - loss: 0.9360\n",
            "Epoch 2/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 74ms/step - accuracy: 0.5113 - loss: 0.8733\n",
            "Epoch 3/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 73ms/step - accuracy: 0.5141 - loss: 0.8199\n",
            "Epoch 4/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 73ms/step - accuracy: 0.5054 - loss: 0.7891\n",
            "Epoch 5/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 74ms/step - accuracy: 0.5083 - loss: 0.7560\n",
            "Epoch 6/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 75ms/step - accuracy: 0.5182 - loss: 0.7271\n",
            "Epoch 7/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 74ms/step - accuracy: 0.5581 - loss: 0.7166\n",
            "Epoch 8/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.7036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oclXwbf_c9P3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4512d7bb-db7c-4cc7-c402-bf577a96a2b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 928ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9964430894308943"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "y_pred = vqkdc_lenet.predict(X_test)\n",
        "accuracy_score(y_test, np.argmax(y_pred, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xONvOKr0hJIj"
      },
      "source": [
        "## Model 2: Mixed QMC variational, QEFF, APA, discriminative with Le-Net Conv layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95ef773c-ba78-4824-8792-6c29cb3b19ca",
        "id": "FaFrZFCLhJI1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 4, 1, 1.0, 123, 123, 0.0005, 12049, 'none', 'discriminative')"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "# Define a LeNet CNN feature extraction model\n",
        "input_shape = X_train.shape[1:]\n",
        "INPUT_DIM = input_shape[0]\n",
        "NUM_QUBITS_FFS = 4 ## originally N_QEFFS = 16\n",
        "NUM_CLASSES = 2\n",
        "NUM_CLASSES_QUBITS = 1\n",
        "DIM_LENET_OUT = 14 # originally 16\n",
        "GAMMA = 1.0 ## originally 2**(0)\n",
        "EPOCHS = 8\n",
        "N_TRAINING_DATA = X_train.shape[0]\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.0005 ## originally 0.0005\n",
        "RANDOM_STATE_QEFF = 123\n",
        "NUM_ANCILLA_QUBITS = 1\n",
        "REDUCTION = \"none\"\n",
        "TRAINING_TYPE = \"discriminative\"\n",
        "\n",
        "EPOCHS, NUM_QUBITS_FFS, NUM_ANCILLA_QUBITS, GAMMA, RANDOM_STATE_QEFF, RANDOM_STATE_QEFF, LEARNING_RATE, N_TRAINING_DATA, REDUCTION, TRAINING_TYPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 792
        },
        "outputId": "fdf05933-19d7-498e-ac3f-d78dc12dd532",
        "id": "poFrYxALhJI2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_22\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_22\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_44 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │             \u001b[38;5;34m520\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_44                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_45 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │          \u001b[38;5;34m25,050\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_45                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_22 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2450\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)                  │         \u001b[38;5;34m205,884\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │           \u001b[38;5;34m1,190\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ quantum_layer_22 (\u001b[38;5;33mQuantumLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m126\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_44                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,050</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_45                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2450</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">205,884</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,190</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ quantum_layer_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">QuantumLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m232,770\u001b[0m (909.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">232,770</span> (909.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m232,770\u001b[0m (909.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">232,770</span> (909.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 81ms/step - accuracy: 0.6142 - loss: 2.5077\n",
            "Epoch 2/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 83ms/step - accuracy: 0.9971 - loss: 0.0551\n",
            "Epoch 3/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 81ms/step - accuracy: 0.9996 - loss: 0.0230\n",
            "Epoch 4/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 81ms/step - accuracy: 0.9995 - loss: 0.0103\n",
            "Epoch 5/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 88ms/step - accuracy: 0.9991 - loss: 0.0092\n",
            "Epoch 6/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 82ms/step - accuracy: 0.9997 - loss: 0.0058\n",
            "Epoch 7/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 81ms/step - accuracy: 0.9999 - loss: 0.0035\n",
            "Epoch 8/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.0038\n"
          ]
        }
      ],
      "source": [
        "## training the quantum circuit\n",
        "vqkdc_lenet = VQKDC_MIXED_QEFF_LENET(n_qeff_qubits = NUM_QUBITS_FFS, n_ancilla_qubits =  NUM_ANCILLA_QUBITS, num_classes_qubits = NUM_CLASSES_QUBITS, num_classes_param = NUM_CLASSES, dim_lenet_out_param = DIM_LENET_OUT, input_dim_param = INPUT_DIM, n_training_data = N_TRAINING_DATA, reduction = REDUCTION, training_type = TRAINING_TYPE, gamma=GAMMA, batch_size = BATCH_SIZE, learning_rate = LEARNING_RATE, random_state = RANDOM_STATE_QEFF)\n",
        "\n",
        "vqkdc_lenet.fit(X_train, y_train_oh, epochs = EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea3708c-539e-49a9-be7c-827a092b5ee5",
        "id": "-2cvvN3phJI4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 916ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9979674796747967"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ],
      "source": [
        "y_pred = vqkdc_lenet.predict(X_test)\n",
        "accuracy_score(y_test, np.argmax(y_pred, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87tkyFrg_RBE"
      },
      "source": [
        "## Model 3: Mixed QMC variational, QEFF, HEA, generative with Le-Net Conv layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QwxuX2obHjA"
      },
      "source": [
        "The number of parameters of the Hardware efficient ansatz is given by,\n",
        "\n",
        "\n",
        "```\n",
        "HEA_size = n_qubits * (num_layers_hea + 1) * 2\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "g_5LrUBY_RBG"
      },
      "outputs": [],
      "source": [
        "### Quantum variational KDC with QEFF\n",
        "\n",
        "import tensorcircuit as tc\n",
        "from tensorcircuit import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import math as m\n",
        "from scipy.stats import entropy, spearmanr\n",
        "\n",
        "\n",
        "\n",
        "tc.set_backend(\"tensorflow\")\n",
        "tc.set_dtype(\"complex128\")\n",
        "\n",
        "pi = tf.constant(m.pi)\n",
        "\n",
        "\n",
        "class VQKDC_MIXED_QEFF_HEA_LENET:\n",
        "    r\"\"\"\n",
        "    Defines the ready-to-use Quantum measurement classification (QMC) model implemented\n",
        "    in TensorCircuit using the TensorFlow/Keras API. Any additional argument in the methods has to be Keras-compliant.\n",
        "\n",
        "    Args:\n",
        "        auto_compile: A boolean to autocompile the model using default settings. (Default True).\n",
        "        var_pure_state_size:\n",
        "        gamma:\n",
        "\n",
        "    Returns:\n",
        "        An instantiated model ready to train with ad-hoc data.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, n_qeff_qubits, n_ancilla_qubits, num_classes_qubits, num_classes_param, dim_lenet_out_param, input_dim_param, gamma, n_training_data,  reduction = \"none\", training_type = \"generative\",  num_layers_hea = 3, batch_size = 16, learning_rate = 0.0005, random_state = 15, auto_compile=True):\n",
        "\n",
        "        self.circuit = None\n",
        "        self.gamma = gamma\n",
        "        self.num_layers_hea = num_layers_hea\n",
        "        self.num_classes = num_classes_param\n",
        "        self.num_classes_qubits = num_classes_qubits\n",
        "        self.n_qeff_qubits = n_qeff_qubits\n",
        "        self.n_ancilla_qubits = n_ancilla_qubits\n",
        "        self.n_total_qubits_temp = self.num_classes_qubits + self.n_qeff_qubits + self.n_ancilla_qubits\n",
        "        self.num_ffs = 2**self.n_qeff_qubits\n",
        "        self.n_training_data = n_training_data\n",
        "        self.dim_lenet_out = dim_lenet_out_param\n",
        "        self.input_dim = input_dim_param\n",
        "        self.var_hea_ansatz_size = int(self.n_total_qubits_temp*(self.num_layers_hea+1)*2)\n",
        "        self.reduction  = reduction\n",
        "        self.training_type = training_type\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.qeff_weights = tf.random.normal((self.dim_lenet_out, int(self.num_ffs*1-1)), mean = 0.0, stddev = 2.0/np.sqrt(self.num_ffs - 1), dtype=tf.dtypes.float64, seed = random_state)\n",
        "\n",
        "        layer = keras.QuantumLayer(\n",
        "            partial(self.layer),\n",
        "            [(self.var_hea_ansatz_size,)]\n",
        "            )\n",
        "\n",
        "        ## build the Let-net model\n",
        "        self.model = Sequential()\n",
        "        self.model.add(tf.keras.layers.Conv2D(filters=20, kernel_size=(5, 5), padding=\"same\", activation='relu', input_shape=(self.input_dim, self.input_dim, 1)))\n",
        "        self.model.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2))\n",
        "        self.model.add(tf.keras.layers.Conv2D(filters=50, kernel_size=(5, 5), padding=\"same\", activation='relu'))\n",
        "        self.model.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2))\n",
        "        self.model.add(tf.keras.layers.Flatten())\n",
        "        self.model.add(tf.keras.layers.Dense(units=84, activation='relu'))\n",
        "        self.model.add(tf.keras.layers.Dense(units=self.dim_lenet_out, activation = 'relu')) # original \"softmax\"\n",
        "\n",
        "        # add the quantum layer\n",
        "\n",
        "        self.model.add(layer)\n",
        "        print(self.model.summary())\n",
        "\n",
        "        if auto_compile:\n",
        "            self.compile()\n",
        "\n",
        "    def layer(\n",
        "            self,\n",
        "            x_sample_param,\n",
        "            var_hea_ansatz_param,\n",
        "        ):\n",
        "        r\"\"\"\n",
        "        Defines a Density Matrix Kernel Density Estimation quantum layer for learning with fixed qaff (Meaning of qaff?). (This function was originally named dmkde_mixed_variational_density_estimation_fixed_qaff)\n",
        "\n",
        "        Args:\n",
        "            U_dagger:\n",
        "            var_pure_state_param:\n",
        "\n",
        "        Returns:\n",
        "            The probabilities of :math:`|k\\rangle`, `|1\\rangle`, ..., `|k\\rangle` state for kernel density classification of the classes.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        ### indices pure state hea\n",
        "        index_iter_hea  = iter(np.arange(len(var_hea_ansatz_param)))\n",
        "\n",
        "        ### indices qeff\n",
        "        index_iter_qeff = iter(np.arange(self.qeff_weights.shape[1]))\n",
        "\n",
        "        ### indices classes, of ms\n",
        "        n_qubits_classes_qeff_temp = self.num_classes_qubits + self.n_qeff_qubits\n",
        "        index_qubit_states = _indices_qubits_classes(n_qubits_classes_qeff_temp, self.num_classes) # extract indices of the bit string of classes\n",
        "\n",
        "\n",
        "        # Instantiate a circuit with the calculated number of qubits.\n",
        "        self.circuit = tc.Circuit(self.n_total_qubits_temp)\n",
        "\n",
        "        def hea_ansatz(qc_param, num_qubits_param, num_layers_param):\n",
        "          # encoding\n",
        "          for i in range (0, num_qubits_param):\n",
        "            qc_param.ry(i, theta = var_hea_ansatz_param[next(index_iter_hea)])\n",
        "            qc_param.rz(i, theta = var_hea_ansatz_param[next(index_iter_hea)])\n",
        "          # layers\n",
        "          for j in range(num_layers_param):\n",
        "            for i in range (0, num_qubits_param-1):\n",
        "              qc_param.CNOT(i, i+1)\n",
        "\n",
        "            for i in range (0, num_qubits_param):\n",
        "              qc_param.ry(i, theta= var_hea_ansatz_param[next(index_iter_hea)])\n",
        "              qc_param.rz(i, theta= var_hea_ansatz_param[next(index_iter_hea)])\n",
        "\n",
        "        ## learning pure state with HEA\n",
        "        hea_ansatz(self.circuit, self.n_total_qubits_temp, self.num_layers_hea)\n",
        "\n",
        "        # Value to predict\n",
        "\n",
        "        x_sample_temp = tf.expand_dims(x_sample_param, axis=0)\n",
        "        phases_temp = (tf.cast(tf.sqrt(self.gamma), tf.float64)*tf.linalg.matmul(tf.cast(x_sample_temp, tf.float64), self.qeff_weights))[0]\n",
        "        init_qubit_qeff_temp = self.num_classes_qubits # qubit at which the qaff mapping starts it starts after the qubits of the classes\n",
        "\n",
        "        def circuit_base_rz_qeff_n(qc_param, num_qubits_param, target_qubit_param, init_qubit_param):\n",
        "          if num_qubits_param == 1:\n",
        "            qc_param.rz(init_qubit_param, theta = phases_temp[next(index_iter_qeff)] )\n",
        "          elif num_qubits_param == 2:\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[next(index_iter_qeff)])\n",
        "            qc_param.cnot(init_qubit_param, target_qubit_param + init_qubit_param)\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[next(index_iter_qeff)])\n",
        "            return\n",
        "          else:\n",
        "            circuit_base_rz_qeff_n(qc_param, num_qubits_param-1, target_qubit_param, init_qubit_param)\n",
        "            qc_param.cnot(num_qubits_param-2 + init_qubit_param, target_qubit_param + init_qubit_param)\n",
        "            circuit_base_rz_qeff_n(qc_param, num_qubits_param-1, target_qubit_param, init_qubit_param)\n",
        "            target_qubit_param -= 1\n",
        "\n",
        "        # Applying the QEFF feature map\n",
        "\n",
        "        for i in reversed(range(1, self.n_qeff_qubits + 1)):\n",
        "          circuit_base_rz_qeff_n(self.circuit, i, i - 1, init_qubit_qeff_temp)\n",
        "\n",
        "        for i in range(init_qubit_qeff_temp, init_qubit_qeff_temp + self.n_qeff_qubits):\n",
        "          self.circuit.H(i)\n",
        "\n",
        "        # Trace out ancilla qubits, find probability of [000] state for density estimation\n",
        "        measurement_state = tc.quantum.reduced_density_matrix(\n",
        "                        self.circuit.state(),\n",
        "                        cut=[m for m in range(n_qubits_classes_qeff_temp, self.n_total_qubits_temp)])\n",
        "        measurements_results = tc.backend.real(tf.stack([measurement_state[index_qubit_states[i], index_qubit_states[i]] for i in range(self.num_classes)]))\n",
        "        if self.training_type == \"discriminative\":\n",
        "          measurements_results = measurements_results / tf.reduce_sum(measurements_results, axis = -1)\n",
        "        return measurements_results\n",
        "\n",
        "    def custom_categorical_crossentropy(self, y_true, y_pred):\n",
        "      ## code generated with the aid of chat gpt\n",
        "      \"\"\"\n",
        "      Compute the categorical cross-entropy loss with mean reduction.\n",
        "\n",
        "      Args:\n",
        "      y_true: Tensor of true labels, shape (batch_size, num_classes).\n",
        "      y_pred: Tensor of predicted probabilities, shape (batch_size, num_classes).\n",
        "\n",
        "      Returns:\n",
        "      Scalar tensor representing the mean loss over the batch.\n",
        "      \"\"\"\n",
        "      # Ensure predictions are clipped to avoid log(0)\n",
        "      epsilon_two = 1e-7  # small constant to avoid division by zero\n",
        "      y_pred = tf.clip_by_value(y_pred, epsilon_two, np.inf)  # clip values to avoid log(0) originaly 1.0 - epsilon\n",
        "\n",
        "      # Compute the categorical cross-entropy loss for each sample\n",
        "      loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
        "\n",
        "      if self.reduction == \"none\":\n",
        "        return loss\n",
        "      elif self.reduction == \"mean\":\n",
        "        # Compute the mean loss over the batch\n",
        "        mean_loss = tf.reduce_mean(loss)\n",
        "        return mean_loss\n",
        "      elif self.reduction == \"sum\":\n",
        "        # Compute the sum loss over the batch\n",
        "        sum_loss = tf.reduce_sum(loss)\n",
        "        return sum_loss\n",
        "      else:\n",
        "        return loss\n",
        "\n",
        "    def compile(\n",
        "            self,\n",
        "            optimizer=tf.keras.optimizers.Adam,\n",
        "            **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to compile the model.\n",
        "\n",
        "        Args:\n",
        "            optimizer:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "        self.model.compile(\n",
        "            loss = self.custom_categorical_crossentropy,\n",
        "            optimizer=optimizer(self.learning_rate),\n",
        "            metrics=[\"accuracy\"],\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "    def fit(self, x_train, y_train, batch_size=16, epochs = 30, **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to fit (train) the model using the ad-hoc dataset.\n",
        "\n",
        "        Args:\n",
        "            x_train:\n",
        "            y_train:\n",
        "            batch_size:\n",
        "            epochs:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model.fit(x_train, y_train, batch_size = self.batch_size, epochs = epochs, **kwargs)\n",
        "\n",
        "    def predict(self, x_test):\n",
        "      r\"\"\"\n",
        "      Method to make predictions with the trained model.\n",
        "\n",
        "      Args:\n",
        "          x_test:\n",
        "\n",
        "      Returns:\n",
        "          The predictions of the conditional density estimation of the input data.\n",
        "      \"\"\"\n",
        "      return (tf.experimental.numpy.power((self.gamma/(pi)), self.dim_lenet_out/2.)*\\\n",
        "          self.model.predict(x_test)).numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b7f1e7f-4517-41ff-d22e-78ec76a43140",
        "id": "9r54TIFYDc9l"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16, 4, 1, 1.0, 123, 123, 0.0005, 12049, 'none', 'generative')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Define a LeNet CNN feature extraction model\n",
        "input_shape = X_train.shape[1:]\n",
        "INPUT_DIM = input_shape[0]\n",
        "NUM_QUBITS_FFS = 4 ## originally N_QEFFS = 16\n",
        "NUM_CLASSES = 2\n",
        "NUM_CLASSES_QUBITS = 1\n",
        "DIM_LENET_OUT = 14 # originally 16\n",
        "GAMMA = 1.0 ## originally 2**(0)\n",
        "EPOCHS = 16 ## originally 8\n",
        "N_TRAINING_DATA = X_train.shape[0]\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.0005 ## originally 0.0005\n",
        "RANDOM_STATE_QEFF = 123\n",
        "NUM_LAYERS_HEA = 4 ### 4 for final experiments\n",
        "NUM_ANCILLA_QUBITS = 1\n",
        "REDUCTION = \"none\"\n",
        "TRAINING_TYPE = \"generative\"\n",
        "\n",
        "EPOCHS, NUM_QUBITS_FFS, NUM_ANCILLA_QUBITS, GAMMA, RANDOM_STATE_QEFF, RANDOM_STATE_QEFF, LEARNING_RATE, N_TRAINING_DATA, REDUCTION, TRAINING_TYPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9998a62d-aba9-4b82-f532-4aeace3115a3",
        "id": "rzeIuuadDc9m"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │             \u001b[38;5;34m520\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_6                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │          \u001b[38;5;34m25,050\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_7                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2450\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)                  │         \u001b[38;5;34m205,884\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │           \u001b[38;5;34m1,190\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ quantum_layer_3 (\u001b[38;5;33mQuantumLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m60\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_6                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,050</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_7                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2450</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">205,884</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,190</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ quantum_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">QuantumLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m232,704\u001b[0m (909.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">232,704</span> (909.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m232,704\u001b[0m (909.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">232,704</span> (909.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/16\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 74ms/step - accuracy: 0.5185 - loss: 3.2338\n",
            "Epoch 2/16\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 74ms/step - accuracy: 0.6110 - loss: 1.8772\n",
            "Epoch 3/16\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 75ms/step - accuracy: 0.9998 - loss: 1.3429\n",
            "Epoch 4/16\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 1.0991\n",
            "Epoch 5/16\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.9418\n",
            "Epoch 6/16\n",
            "\u001b[1m249/377\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.8501"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-a3bdcf4dc9f5>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvqkdc_lenet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVQKDC_MIXED_QEFF_HEA_LENET\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_qeff_qubits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_QUBITS_FFS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_ancilla_qubits\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mNUM_ANCILLA_QUBITS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes_qubits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_CLASSES_QUBITS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_lenet_out_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDIM_LENET_OUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINPUT_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_training_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN_TRAINING_DATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mREDUCTION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTRAINING_TYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGAMMA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers_hea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_LAYERS_HEA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRANDOM_STATE_QEFF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvqkdc_lenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_oh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-90d299df93ba>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, batch_size, epochs, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \"\"\"\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "## training the quantum circuit\n",
        "vqkdc_lenet = VQKDC_MIXED_QEFF_HEA_LENET(n_qeff_qubits = NUM_QUBITS_FFS, n_ancilla_qubits =  NUM_ANCILLA_QUBITS, num_classes_qubits = NUM_CLASSES_QUBITS, num_classes_param = NUM_CLASSES, dim_lenet_out_param = DIM_LENET_OUT, input_dim_param = INPUT_DIM, n_training_data = N_TRAINING_DATA, reduction = REDUCTION, training_type = TRAINING_TYPE, gamma=GAMMA, num_layers_hea = NUM_LAYERS_HEA, batch_size = BATCH_SIZE, learning_rate = LEARNING_RATE, random_state = RANDOM_STATE_QEFF)\n",
        "\n",
        "vqkdc_lenet.fit(X_train, y_train_oh, epochs = EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vqkdc_lenet.fit(X_train, y_train_oh, epochs = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4PAbHnBE-97",
        "outputId": "2566f4d7-0903-433e-ae60-29ab7a14ae96"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 74ms/step - accuracy: 0.9999 - loss: 0.8045\n",
            "Epoch 2/5\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.7674\n",
            "Epoch 3/5\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.7455\n",
            "Epoch 4/5\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.7330\n",
            "Epoch 5/5\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.7250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ae3dedc-aa40-47a9-d56b-b55b4f8cd6f2",
        "id": "XqVDnZPFDc9n"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 338ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "y_pred = vqkdc_lenet.predict(X_test)\n",
        "accuracy_score(y_test, np.argmax(y_pred, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tmZCG7ODXNA"
      },
      "source": [
        "## Model 4: Mixed QMC variational, QEFF, HEA, discriminative with Le-Net Conv layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL4MwA0RDXNA"
      },
      "source": [
        "The number of parameters of the Hardware efficient ansatz is given by,\n",
        "\n",
        "\n",
        "```\n",
        "HEA_size = n_qubits * (num_layers_hea + 1) * 2\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6463d7b-7d87-49cf-d758-f66ca6241d52",
        "id": "E_sB3qAS_RBH"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 4, 1, 1.0, 123, 123, 0.0005, 12049, 'none', 'discriminative')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Define a LeNet CNN feature extraction model\n",
        "input_shape = X_train.shape[1:]\n",
        "INPUT_DIM = input_shape[0]\n",
        "NUM_QUBITS_FFS = 4 ## originally N_QEFFS = 16\n",
        "NUM_CLASSES = 2\n",
        "NUM_CLASSES_QUBITS = 1\n",
        "DIM_LENET_OUT = 14 # originally 16\n",
        "GAMMA = 1.0 ## originally 2**(0)\n",
        "EPOCHS = 8\n",
        "N_TRAINING_DATA = X_train.shape[0]\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.0005 ## originally 0.0005\n",
        "RANDOM_STATE_QEFF = 123\n",
        "NUM_LAYERS_HEA = 4 ### 4 HEA layers for final experiments\n",
        "NUM_ANCILLA_QUBITS = 1\n",
        "REDUCTION = \"none\"\n",
        "TRAINING_TYPE = \"discriminative\"\n",
        "\n",
        "EPOCHS, NUM_QUBITS_FFS, NUM_ANCILLA_QUBITS, GAMMA, RANDOM_STATE_QEFF, RANDOM_STATE_QEFF, LEARNING_RATE, N_TRAINING_DATA, REDUCTION, TRAINING_TYPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "outputId": "3b2f5247-416c-4dfc-ed23-09b8fe252924",
        "id": "SXMGtm77_RBH"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │             \u001b[38;5;34m520\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_8                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │          \u001b[38;5;34m25,050\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_9                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2450\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)                  │         \u001b[38;5;34m205,884\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │           \u001b[38;5;34m1,190\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ quantum_layer_4 (\u001b[38;5;33mQuantumLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m60\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_8                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,050</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_9                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2450</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">205,884</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,190</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ quantum_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">QuantumLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m232,704\u001b[0m (909.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">232,704</span> (909.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m232,704\u001b[0m (909.23 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">232,704</span> (909.23 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 73ms/step - accuracy: 0.6952 - loss: 0.6952\n",
            "Epoch 2/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 73ms/step - accuracy: 0.9993 - loss: 0.0074\n",
            "Epoch 3/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 72ms/step - accuracy: 0.9998 - loss: 0.0028\n",
            "Epoch 4/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0017\n",
            "Epoch 5/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 6/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 77ms/step - accuracy: 1.0000 - loss: 0.0012\n",
            "Epoch 7/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 75ms/step - accuracy: 0.9996 - loss: 0.0043\n",
            "Epoch 8/8\n",
            "\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 6.0637e-04\n"
          ]
        }
      ],
      "source": [
        "## training the quantum circuit\n",
        "vqkdc_lenet = VQKDC_MIXED_QEFF_HEA_LENET(n_qeff_qubits = NUM_QUBITS_FFS, n_ancilla_qubits =  NUM_ANCILLA_QUBITS, num_classes_qubits = NUM_CLASSES_QUBITS, num_classes_param = NUM_CLASSES, dim_lenet_out_param = DIM_LENET_OUT, input_dim_param = INPUT_DIM, n_training_data = N_TRAINING_DATA, reduction = REDUCTION, training_type = TRAINING_TYPE, gamma=GAMMA, num_layers_hea = NUM_LAYERS_HEA, batch_size = BATCH_SIZE, learning_rate = LEARNING_RATE, random_state = RANDOM_STATE_QEFF)\n",
        "\n",
        "vqkdc_lenet.fit(X_train, y_train_oh, epochs = EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49da0348-2a23-4886-ee60-2eac4e140f60",
        "id": "ll_ZI4Ki_RBI"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 353ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9989837398373984"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "y_pred = vqkdc_lenet.predict(X_test)\n",
        "accuracy_score(y_test, np.argmax(y_pred, axis=1))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}