{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7VwQfaCOcok"
      },
      "source": [
        "## Quantum Measurement Classification with Pure States on Ten Classes MNIST with quantum-enhanced Fourier features\n",
        "\n",
        "Diego Useche"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU"
      ],
      "metadata": {
        "id": "Px6NXiW6Q74M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al0mmMn7Q9oM",
        "outputId": "05d2e4c0-c41b-435d-97b3-0c5149039969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "HPeuojM4RUB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install tensorcircuit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5IafHoCOqgN",
        "outputId": "819326dd-fa58-4655-9a04-e06d8e2a0ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorcircuit\n",
            "  Downloading tensorcircuit-0.12.0-py3-none-any.whl (342 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.0/342.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorcircuit) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tensorcircuit) (1.11.4)\n",
            "Collecting tensornetwork-ng (from tensorcircuit)\n",
            "  Downloading tensornetwork_ng-0.5.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from tensorcircuit) (3.2.1)\n",
            "Requirement already satisfied: graphviz>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from tensornetwork-ng->tensorcircuit) (0.20.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from tensornetwork-ng->tensorcircuit) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensornetwork-ng->tensorcircuit) (3.9.0)\n",
            "Installing collected packages: tensornetwork-ng, tensorcircuit\n",
            "Successfully installed tensorcircuit-0.12.0 tensornetwork-ng-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15DqVUX2Ocop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "536dd99a-173e-4f0c-eafb-ebdc2d7e9ad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorcircuit.translation:Please first ``pip install -U qiskit`` to enable related functionality in translation module\n",
            "WARNING:tensorcircuit.translation:Please first ``pip install -U cirq`` to enable related functionality in translation module\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorcircuit as tc\n",
        "from tensorcircuit import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzQg29OoOcos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b92652-b9f7-48ff-c298-123f19de9670"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('complex128', 'float64')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "tc.set_backend(\"tensorflow\")\n",
        "tc.set_dtype(\"complex128\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils functions"
      ],
      "metadata": {
        "id": "XHUQ385IUKo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this function takes the number of classes and of qubits of the qmc pure, and extract the indices\n",
        "# of the bit strings that correpond to the classes prediction\n",
        "## Example, qmc prediction bit string [\"00\", \"01\", \"10\", \"11\"]\n",
        "## the classes prediction is encoded in [\"00\", \"10\"], then it returns [0, 2]\n",
        "\n",
        "def indices_qubits_clases(num_qubits_param, num_classes_param):\n",
        "  num_qubits_classes_temp = int(np.ceil(np.log2(num_classes_param)))\n",
        "  a = [np.binary_repr(i, num_qubits_param) for i in range(2**num_qubits_param)]\n",
        "  b = [(np.binary_repr(i, num_qubits_classes_temp) + \"0\"*(num_qubits_param - num_qubits_classes_temp)) for i in range(num_classes_param)]\n",
        "  indices_temp = []\n",
        "  for i in range(len(a)):\n",
        "    if a[i] in b:\n",
        "      indices_temp.append(i)\n",
        "\n",
        "  return indices_temp\n",
        "\n",
        "indices_qubits_clases(4, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcxPN_lIUNI0",
        "outputId": "81e70e5d-003e-4687-c481-f8c52f8a88f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 4, 8, 12]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9OHBspfbc5Z"
      },
      "source": [
        "## MNIST Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhIFHcFRNjuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15768d56-9913-454b-c898-8a042fbeb25b"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train, X_test = X_train[..., np.newaxis]/255.0, X_test[..., np.newaxis]/255.0\n",
        "\n",
        "# Resize images to 4x4\n",
        "img_compress_size = 8\n",
        "X_train = tf.image.resize(X_train, (img_compress_size, img_compress_size)).numpy().reshape(-1, img_compress_size, img_compress_size)\n",
        "X_test = tf.image.resize(X_test, (img_compress_size , img_compress_size)).numpy().reshape(-1, img_compress_size, img_compress_size)\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 8, 8), (10000, 8, 8), (60000,), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI4FC6dsj4a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa04d42-5b61-4c8c-9bd3-206b56e92654"
      },
      "source": [
        "# Select the indices for the binary classification\n",
        "y_train = y_train[:, np.newaxis]\n",
        "y_test = y_test[:, np.newaxis]\n",
        "y_train_oh = tf.reshape (tf.keras.backend.one_hot(y_train, 10), (-1,10))\n",
        "y_test_oh = tf.reshape (tf.keras.backend.one_hot(y_test, 10), (-1,10))\n",
        "\n",
        "# reshape the X_train_n , and X_test_n,\n",
        "n_train = X_train.shape[0]\n",
        "n_test = X_test.shape[0]\n",
        "l_side = X_test.shape[1]\n",
        "X_train = X_train.reshape((n_train, l_side**2))\n",
        "X_test = X_test.reshape((n_test, l_side**2))\n",
        "\n",
        "X_train.shape, X_test.shape, y_train_oh.shape, y_test_oh.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 64), (10000, 64), TensorShape([60000, 10]), TensorShape([10000, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: Mixed QMC, QEFF, No-conv layer\n",
        "\n",
        "Ten classes MNIST Classification, QMC variational, with quantum-enhanced Fourier features, no-conv layer"
      ],
      "metadata": {
        "id": "lqfVvzNb1BZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this function takes the number of classes and of qubits of the qmc pure, and extract the indices\n",
        "# of the bit strings that correpond to the classes prediction\n",
        "def indices_qubits_clases(num_qubits_param, num_classes_param):\n",
        "  num_qubits_classes_temp = int(np.ceil(np.log2(num_classes_param)))\n",
        "  a = [np.binary_repr(i, num_qubits_param) for i in range(2**num_qubits_param)]\n",
        "  b = [(np.binary_repr(i, num_qubits_classes_temp) + \"0\"*(num_qubits_param - num_qubits_classes_temp)) for i in range(num_classes_param)]\n",
        "  indices_temp = []\n",
        "  for i in range(len(a)):\n",
        "    if a[i] in b:\n",
        "      indices_temp.append(i)\n",
        "\n",
        "  return indices_temp\n",
        "\n",
        "indices_qubits_clases(6, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4LLe5VvQaYH",
        "outputId": "3fa139b7-38b9-471d-9c72-73a10e097395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 4, 8, 12, 16, 20, 24, 28, 32, 36]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Quantum variational KDC with QEFF\n",
        "\n",
        "import tensorcircuit as tc\n",
        "from tensorcircuit import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import math as m\n",
        "from scipy.stats import entropy, spearmanr\n",
        "\n",
        "\n",
        "\n",
        "tc.set_backend(\"tensorflow\")\n",
        "tc.set_dtype(\"complex128\")\n",
        "\n",
        "pi = tf.constant(m.pi)\n",
        "\n",
        "\n",
        "class QVKDC_MIXED_QEFF:\n",
        "    r\"\"\"\n",
        "    Defines the ready-to-use Quantum measurement classification (QMC) model implemented\n",
        "    in TensorCircuit using the TensorFlow/Keras API. Any additional argument in the methods has to be Keras-compliant.\n",
        "\n",
        "    Args:\n",
        "        auto_compile: A boolean to autocompile the model using default settings. (Default True).\n",
        "        var_pure_state_size:\n",
        "        gamma:\n",
        "\n",
        "    Returns:\n",
        "        An instantiated model ready to train with ad-hoc data.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, qeff_weights_param, num_classes_param, auto_compile=True, var_pure_state_size=64, gamma=2., epochs_param=15):\n",
        "\n",
        "        self.circuit = None\n",
        "        self.gamma = gamma\n",
        "        self.num_classes = num_classes_param\n",
        "        self.var_pure_state_parameters_size = 2*var_pure_state_size - 2\n",
        "        self.qeff_weights_param =  qeff_weights_param\n",
        "        self.epochs = epochs_param\n",
        "\n",
        "        layer = keras.QuantumLayer(\n",
        "            partial(self.layer),\n",
        "            [(self.var_pure_state_parameters_size,)]\n",
        "            )\n",
        "\n",
        "        self.model = tf.keras.Sequential([layer])\n",
        "\n",
        "        if auto_compile:\n",
        "            self.compile()\n",
        "\n",
        "    def layer(\n",
        "            self,\n",
        "            x_sample_param,\n",
        "            var_pure_state_param,\n",
        "        ):\n",
        "        r\"\"\"\n",
        "        Defines a Density Matrix Kernel Density Estimation quantum layer for learning with fixed qaff (Meaning of qaff?). (This function was originally named dmkde_mixed_variational_density_estimation_fixed_qaff)\n",
        "\n",
        "        Args:\n",
        "            U_dagger:\n",
        "            var_pure_state_param:\n",
        "\n",
        "        Returns:\n",
        "            The probabilities of :math:`|k\\rangle`, `|1\\rangle`, ..., `|k\\rangle` state for kernel density classification of the classes.\n",
        "        \"\"\"\n",
        "\n",
        "        n_total_qubits_temp = int(np.log2((len(var_pure_state_param)+2)/2))\n",
        "        n_qeffs_temp = int((self.qeff_weights_param.shape[1] + 2)/2)\n",
        "        n_qubits_classes_qeff_temp = int(np.ceil(np.log2((self.num_classes))+np.ceil(np.log2((n_qeffs_temp)))))\n",
        "        n_qeff_qubits_temp = int(np.ceil(np.log2((n_qeffs_temp))))\n",
        "        n_classes_qubits_temp = int(np.ceil(np.log2(self.num_classes)))\n",
        "\n",
        "        ### iterators qeff, ps\n",
        "        index_iter_qeff = iter(np.arange(self.qeff_weights_param.shape[1]))\n",
        "        index_iter_ps  = iter(np.arange(len(var_pure_state_param)))\n",
        "\n",
        "        ### indices classes, of ms\n",
        "        index_qubit_states = indices_qubits_clases(n_qubits_classes_qeff_temp, self.num_classes) # extract indices of the bit string of classes\n",
        "\n",
        "        # Instantiate a circuit with the calculated number of qubits.\n",
        "        self.circuit = tc.Circuit(n_total_qubits_temp)\n",
        "\n",
        "        def circuit_base_ry_n(qc_param, num_qubits_param, target_qubit_param):\n",
        "            if num_qubits_param == 1:\n",
        "                qc_param.ry(0, theta = var_pure_state_param[next(index_iter_ps)])\n",
        "            elif num_qubits_param == 2:\n",
        "                qc_param.ry(target_qubit_param, theta=var_pure_state_param[next(index_iter_ps)])\n",
        "                qc_param.cnot(0, target_qubit_param)\n",
        "                qc_param.ry(target_qubit_param, theta=var_pure_state_param[next(index_iter_ps)])\n",
        "                return\n",
        "            else:\n",
        "                circuit_base_ry_n(qc_param, num_qubits_param-1, target_qubit_param)\n",
        "                qc_param.cnot(num_qubits_param-2, target_qubit_param)\n",
        "                circuit_base_ry_n(qc_param, num_qubits_param-1, target_qubit_param)\n",
        "                target_qubit_param -= 1\n",
        "\n",
        "        def circuit_base_rz_n(qc_param, num_qubits_param, target_qubit_param):\n",
        "            if num_qubits_param == 1:\n",
        "                qc_param.rz(0, theta = var_pure_state_param[next(index_iter_ps)])\n",
        "            elif num_qubits_param == 2:\n",
        "                qc_param.rz(target_qubit_param, theta=var_pure_state_param[next(index_iter_ps)])\n",
        "                qc_param.cnot(0, target_qubit_param)\n",
        "                qc_param.rz(target_qubit_param, theta=var_pure_state_param[next(index_iter_ps)])\n",
        "                return\n",
        "            else:\n",
        "                circuit_base_rz_n(qc_param, num_qubits_param-1, target_qubit_param)\n",
        "                qc_param.cnot(num_qubits_param-2, target_qubit_param)\n",
        "                circuit_base_rz_n(qc_param, num_qubits_param-1, target_qubit_param)\n",
        "                target_qubit_param -= 1\n",
        "\n",
        "        # Learning pure state\n",
        "        for i in range(1, n_total_qubits_temp+1):\n",
        "            circuit_base_ry_n(self.circuit, i, i-1)\n",
        "\n",
        "        # Learning pure state complex phase\n",
        "        for j in range(1, n_total_qubits_temp+1):\n",
        "            circuit_base_rz_n(self.circuit, j, j-1)\n",
        "\n",
        "        # Value to predict\n",
        "\n",
        "        x_sample_temp = tf.expand_dims(x_sample_param, axis=0)\n",
        "        phases_temp = tf.cast(tf.sqrt(self.gamma), tf.float64)*tf.linalg.matmul(tf.cast(x_sample_temp, tf.float64), self.qeff_weights_param)\n",
        "        init_qubit_qeff_temp = n_classes_qubits_temp # qubit at which the qaff mapping starts it starts after the qubits of the classes\n",
        "\n",
        "        def circuit_base_rz_qeff_n(qc_param, num_qubits_param, target_qubit_param, init_qubit_param):\n",
        "          if num_qubits_param == 1:\n",
        "            qc_param.rz(init_qubit_param, theta = phases_temp[0][next(index_iter_qeff)])\n",
        "            qc_param.X(init_qubit_param)\n",
        "            qc_param.rz(init_qubit_param, theta = phases_temp[0][next(index_iter_qeff)])\n",
        "          elif num_qubits_param == 2:\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[0][next(index_iter_qeff)])\n",
        "            qc_param.X(target_qubit_param + init_qubit_param)\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[0][next(index_iter_qeff)])\n",
        "            qc_param.cnot(init_qubit_param, target_qubit_param + init_qubit_param)\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[0][next(index_iter_qeff)])\n",
        "            qc_param.X(target_qubit_param + init_qubit_param)\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[0][next(index_iter_qeff)])\n",
        "            return\n",
        "          else:\n",
        "            circuit_base_rz_qeff_n(qc_param, num_qubits_param-1, target_qubit_param, init_qubit_param)\n",
        "            qc_param.cnot(num_qubits_param-2+init_qubit_param, target_qubit_param+init_qubit_param)\n",
        "            circuit_base_rz_qeff_n(qc_param, num_qubits_param-1, target_qubit_param, init_qubit_param)\n",
        "            target_qubit_param -= 1\n",
        "\n",
        "        # Applying the QEFF feature map\n",
        "\n",
        "        for i in range(n_qubits_classes_qeff_temp - init_qubit_qeff_temp + 1 - 1, 1 - 1, -1):\n",
        "          circuit_base_rz_qeff_n(self.circuit, i, i - 1, init_qubit_qeff_temp)\n",
        "\n",
        "        for i in range(init_qubit_qeff_temp, n_qubits_classes_qeff_temp):\n",
        "          self.circuit.H(i)\n",
        "\n",
        "        # Trace out ancilla qubits, find probability of |k> state for the prediction of class k\n",
        "\n",
        "        measurement_state = tc.quantum.reduced_density_matrix(self.circuit.state(), cut=[m for m in range(n_qubits_classes_qeff_temp, n_total_qubits_temp)])\n",
        "        measurements_results = (1./(self.epochs))*tc.backend.real(tf.stack([measurement_state[index_qubit_states[i], index_qubit_states[i]] for i in range(self.num_classes)]))\n",
        "        return measurements_results\n",
        "\n",
        "    def compile(\n",
        "            self,\n",
        "            optimizer=tf.keras.optimizers.legacy.Adam(0.0005), # originally 0.0005\n",
        "            **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to compile the model.\n",
        "\n",
        "        Args:\n",
        "            optimizer:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "        self.model.compile(\n",
        "            loss = \"categorical_crossentropy\",\n",
        "            optimizer=optimizer,\n",
        "            metrics=[\"accuracy\"],\n",
        "            **kwargs\n",
        "        )\n",
        "    def fit(self, x_train, y_train, batch_size=16, **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to fit (train) the model using the ad-hoc dataset.\n",
        "\n",
        "        Args:\n",
        "            x_train:\n",
        "            y_train:\n",
        "            batch_size:\n",
        "            epochs:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model.fit(x_train, y_train, batch_size=batch_size, epochs=self.epochs, **kwargs)\n",
        "\n",
        "    def predict(self, x_test):\n",
        "      r\"\"\"\n",
        "      Method to make predictions with the trained model.\n",
        "\n",
        "      Args:\n",
        "          x_test:\n",
        "\n",
        "      Returns:\n",
        "          The predictions of the conditional density estimation of the input data.\n",
        "      \"\"\"\n",
        "      print(x_test.shape[1])\n",
        "      return (tf.power((self.gamma/(pi)), x_test.shape[1])*\\\n",
        "          self.model.predict(x_test)).numpy()\n"
      ],
      "metadata": {
        "id": "XU5IHJxQ2Kk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b172dc-38ff-4155-d851-bfbd5dc160de",
        "id": "tZ4_4NBhbv5W"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.0003616293817530976, 0.3825734149174446, (64, 14), 60000)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "N_QEFFS = 8\n",
        "NUM_CLASSES = 10\n",
        "dim_x = 8**2 # 8x8 images\n",
        "GAMMA = 2**(-2) # originally 2**(-4)\n",
        "num_data = X_train.shape[0]\n",
        "EPOCHS = 10\n",
        "PURE_STATE_SIZE = 256\n",
        "\n",
        "weights_qeff_method = np.random.normal(size=(X_train.shape[1], 2*(N_QEFFS-1)))/np.sqrt((N_QEFFS-1))\n",
        "\n",
        "weights_qeff_method.mean(), weights_qeff_method.std(), weights_qeff_method.shape, num_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qvkdc = QVKDC_MIXED_QEFF(qeff_weights_param = weights_qeff_method, num_classes_param = NUM_CLASSES, var_pure_state_size=PURE_STATE_SIZE, gamma=GAMMA, epochs_param = EPOCHS)\n",
        "\n",
        "qvkdc.fit(X_train, y_train_oh, batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "bjTRbjgzBd02",
        "outputId": "dbfd44bc-785c-47ff-e221-f19700271126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3750/3750 [==============================] - 507s 67ms/step - loss: 2.9741 - accuracy: 0.1977\n",
            "Epoch 2/10\n",
            "3750/3750 [==============================] - 211s 56ms/step - loss: 1.7899 - accuracy: 0.3885\n",
            "Epoch 3/10\n",
            "3750/3750 [==============================] - 268s 71ms/step - loss: 1.7135 - accuracy: 0.4204\n",
            "Epoch 4/10\n",
            "3750/3750 [==============================] - 287s 77ms/step - loss: 1.6983 - accuracy: 0.4268\n",
            "Epoch 5/10\n",
            " 276/3750 [=>............................] - ETA: 3:09 - loss: 1.6998 - accuracy: 0.4198"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-8d483f4be406>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mqvkdc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQVKDC_MIXED_QEFF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqeff_weights_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights_qeff_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_pure_state_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPURE_STATE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGAMMA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mqvkdc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_oh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-d820f0abe999>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: Mixed QMC variational, QEFF, with Le-Net Conv layer"
      ],
      "metadata": {
        "id": "6z_TNB4x19Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Libraries"
      ],
      "metadata": {
        "id": "ElP-3g_shd7A"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyl7-JSjyuCe",
        "outputId": "7158de1f-f0ec-4cfe-ec71-09b4ecdcb9f1"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_logical_devices())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n",
            "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKnjjaDGwwOe"
      },
      "source": [
        "### MNIST Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c15c086-38ce-49a8-dd0a-c163316ed808",
        "id": "7mEENez9wwOu"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train, X_test = X_train[..., np.newaxis]/255.0, X_test[..., np.newaxis]/255.0\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (10000, 28, 28, 1), (60000,), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ba35df9-c5e5-4af2-ce78-5eb2bf902ff4",
        "id": "5tJeZb9xwwOu"
      },
      "source": [
        "# Select the indices for the binary classification\n",
        "y_train = y_train[:, np.newaxis]\n",
        "y_test = y_test[:, np.newaxis]\n",
        "y_train_oh = tf.reshape (tf.keras.backend.one_hot(y_train, 10), (-1,10))\n",
        "y_test_oh = tf.reshape (tf.keras.backend.one_hot(y_test, 10), (-1,10))\n",
        "\n",
        "X_train.shape, X_test.shape, y_train_oh.shape, y_test_oh.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1),\n",
              " (10000, 28, 28, 1),\n",
              " TensorShape([60000, 10]),\n",
              " TensorShape([10000, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_logical_devices())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9WIiZJf6TNv",
        "outputId": "f7b0911f-edbc-430f-9fc4-d20a55398a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n",
            "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Quantum variational KDC with QEFF\n",
        "\n",
        "import tensorcircuit as tc\n",
        "from tensorcircuit import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import math as m\n",
        "from scipy.stats import entropy, spearmanr\n",
        "\n",
        "\n",
        "\n",
        "tc.set_backend(\"tensorflow\")\n",
        "tc.set_dtype(\"complex128\")\n",
        "\n",
        "pi = tf.constant(m.pi)\n",
        "\n",
        "\n",
        "class QVKDC_MIXED_QEFF_LENET:\n",
        "    r\"\"\"\n",
        "    Defines the ready-to-use Quantum measurement classification (QMC) model implemented\n",
        "    in TensorCircuit using the TensorFlow/Keras API. Any additional argument in the methods has to be Keras-compliant.\n",
        "\n",
        "    Args:\n",
        "        auto_compile: A boolean to autocompile the model using default settings. (Default True).\n",
        "        var_pure_state_size:\n",
        "        gamma:\n",
        "\n",
        "    Returns:\n",
        "        An instantiated model ready to train with ad-hoc data.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, qeff_weights_param, num_classes_param, input_dim_param, dim_lenet_out_param, auto_compile=True, var_pure_state_size=64, gamma=2., epochs_param=15):\n",
        "\n",
        "        self.circuit = None\n",
        "        self.gamma = gamma\n",
        "        self.num_classes = num_classes_param\n",
        "        self.var_pure_state_parameters_size = 2*var_pure_state_size - 2\n",
        "        self.qeff_weights_param =  qeff_weights_param\n",
        "        self.epochs = epochs_param\n",
        "        self.dim_lenet_out = dim_lenet_out_param\n",
        "\n",
        "        layer = keras.QuantumLayer(\n",
        "            partial(self.layer),\n",
        "            [(self.var_pure_state_parameters_size,)]\n",
        "            )\n",
        "\n",
        "        ## build the Let-net model\n",
        "        self.model = Sequential()\n",
        "        self.model.add(tf.keras.layers.Conv2D(filters=20, kernel_size=(5, 5), padding=\"same\", activation='relu', input_shape=(input_dim_param, input_dim_param, 1)))\n",
        "        self.model.add(tf.keras.layers.AveragePooling2D())\n",
        "        self.model.add(tf.keras.layers.Conv2D(filters=50, kernel_size=(5, 5), padding=\"same\", activation='relu'))\n",
        "        self.model.add(tf.keras.layers.AveragePooling2D())\n",
        "        self.model.add(tf.keras.layers.Flatten())\n",
        "        self.model.add(tf.keras.layers.Dense(units=84, activation='relu'))\n",
        "        self.model.add(tf.keras.layers.Dense(units=self.dim_lenet_out, activation = 'relu')) # original \"softmax\"\n",
        "\n",
        "        # add the quantum layer\n",
        "\n",
        "        self.model.add(layer)\n",
        "\n",
        "        if auto_compile:\n",
        "            self.compile()\n",
        "\n",
        "    def layer(\n",
        "            self,\n",
        "            x_sample_param,\n",
        "            var_pure_state_param,\n",
        "        ):\n",
        "        r\"\"\"\n",
        "        Defines a Density Matrix Kernel Density Estimation quantum layer for learning with fixed qaff (Meaning of qaff?). (This function was originally named dmkde_mixed_variational_density_estimation_fixed_qaff)\n",
        "\n",
        "        Args:\n",
        "            U_dagger:\n",
        "            var_pure_state_param:\n",
        "\n",
        "        Returns:\n",
        "            The probabilities of :math:`|k\\rangle`, `|1\\rangle`, ..., `|k\\rangle` state for kernel density classification of the classes.\n",
        "        \"\"\"\n",
        "\n",
        "        n_total_qubits_temp = int(np.log2((len(var_pure_state_param)+2)/2))\n",
        "        n_qeffs_temp = int((self.qeff_weights_param.shape[1] + 2)/2)\n",
        "        n_qubits_classes_qeff_temp = int(np.ceil(np.log2((self.num_classes))+np.ceil(np.log2((n_qeffs_temp)))))\n",
        "        n_qeff_qubits_temp = int(np.ceil(np.log2((n_qeffs_temp))))\n",
        "        n_classes_qubits_temp = int(np.ceil(np.log2(self.num_classes)))\n",
        "\n",
        "        ### iterators qeff, ps\n",
        "        index_iter_qeff = iter(np.arange(self.qeff_weights_param.shape[1]))\n",
        "        index_iter_ps  = iter(np.arange(len(var_pure_state_param)))\n",
        "\n",
        "        ### indices classes, of ms\n",
        "        index_qubit_states = indices_qubits_clases(n_qubits_classes_qeff_temp, self.num_classes) # extract indices of the bit string of classes\n",
        "\n",
        "        # Instantiate a circuit with the calculated number of qubits.\n",
        "        self.circuit = tc.Circuit(n_total_qubits_temp)\n",
        "\n",
        "        def circuit_base_ry_n(qc_param, num_qubits_param, target_qubit_param):\n",
        "            if num_qubits_param == 1:\n",
        "                qc_param.ry(0, theta = var_pure_state_param[next(index_iter_ps)])\n",
        "            elif num_qubits_param == 2:\n",
        "                qc_param.ry(target_qubit_param, theta=var_pure_state_param[next(index_iter_ps)])\n",
        "                qc_param.cnot(0, target_qubit_param)\n",
        "                qc_param.ry(target_qubit_param, theta=var_pure_state_param[next(index_iter_ps)])\n",
        "                return\n",
        "            else:\n",
        "                circuit_base_ry_n(qc_param, num_qubits_param-1, target_qubit_param)\n",
        "                qc_param.cnot(num_qubits_param-2, target_qubit_param)\n",
        "                circuit_base_ry_n(qc_param, num_qubits_param-1, target_qubit_param)\n",
        "                target_qubit_param -= 1\n",
        "\n",
        "        def circuit_base_rz_n(qc_param, num_qubits_param, target_qubit_param):\n",
        "            if num_qubits_param == 1:\n",
        "                qc_param.rz(0, theta = var_pure_state_param[next(index_iter_ps)])\n",
        "            elif num_qubits_param == 2:\n",
        "                qc_param.rz(target_qubit_param, theta=var_pure_state_param[next(index_iter_ps)])\n",
        "                qc_param.cnot(0, target_qubit_param)\n",
        "                qc_param.rz(target_qubit_param, theta=var_pure_state_param[next(index_iter_ps)])\n",
        "                return\n",
        "            else:\n",
        "                circuit_base_rz_n(qc_param, num_qubits_param-1, target_qubit_param)\n",
        "                qc_param.cnot(num_qubits_param-2, target_qubit_param)\n",
        "                circuit_base_rz_n(qc_param, num_qubits_param-1, target_qubit_param)\n",
        "                target_qubit_param -= 1\n",
        "\n",
        "        # Learning pure state\n",
        "        for i in range(1, n_total_qubits_temp+1):\n",
        "            circuit_base_ry_n(self.circuit, i, i-1)\n",
        "\n",
        "        # Learning pure state complex phase\n",
        "        for j in range(1, n_total_qubits_temp+1):\n",
        "            circuit_base_rz_n(self.circuit, j, j-1)\n",
        "\n",
        "        # Value to predict\n",
        "\n",
        "        x_sample_temp = tf.expand_dims(x_sample_param, axis=0)\n",
        "        phases_temp = tf.sqrt(tf.cast(self.gamma, tf.float64))*tf.linalg.matmul(tf.cast(x_sample_temp, tf.float64), self.qeff_weights_param)\n",
        "        init_qubit_qeff_temp = n_classes_qubits_temp # qubit at which the qaff mapping starts it starts after the qubits of the classes\n",
        "\n",
        "        def circuit_base_rz_qeff_n(qc_param, num_qubits_param, target_qubit_param, init_qubit_param):\n",
        "          if num_qubits_param == 1:\n",
        "            qc_param.rz(init_qubit_param, theta = phases_temp[0][next(index_iter_qeff)])\n",
        "            qc_param.X(init_qubit_param)\n",
        "            qc_param.rz(init_qubit_param, theta = phases_temp[0][next(index_iter_qeff)])\n",
        "          elif num_qubits_param == 2:\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[0][next(index_iter_qeff)])\n",
        "            qc_param.X(target_qubit_param + init_qubit_param)\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[0][next(index_iter_qeff)])\n",
        "            qc_param.cnot(init_qubit_param, target_qubit_param + init_qubit_param)\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[0][next(index_iter_qeff)])\n",
        "            qc_param.X(target_qubit_param + init_qubit_param)\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[0][next(index_iter_qeff)])\n",
        "            return\n",
        "          else:\n",
        "            circuit_base_rz_qeff_n(qc_param, num_qubits_param-1, target_qubit_param, init_qubit_param)\n",
        "            qc_param.cnot(num_qubits_param-2+init_qubit_param, target_qubit_param+init_qubit_param)\n",
        "            circuit_base_rz_qeff_n(qc_param, num_qubits_param-1, target_qubit_param, init_qubit_param)\n",
        "            target_qubit_param -= 1\n",
        "\n",
        "        # Applying the QEFF feature map\n",
        "\n",
        "        for i in range(n_qubits_classes_qeff_temp - init_qubit_qeff_temp + 1 - 1, 1 - 1, -1):\n",
        "          circuit_base_rz_qeff_n(self.circuit, i, i - 1, init_qubit_qeff_temp)\n",
        "\n",
        "        for i in range(init_qubit_qeff_temp, n_qubits_classes_qeff_temp):\n",
        "          self.circuit.H(i)\n",
        "\n",
        "        # Trace out ancilla qubits, find probability of |k> state for the prediction of class k\n",
        "\n",
        "        measurement_state = tc.quantum.reduced_density_matrix(self.circuit.state(), cut=[m for m in range(n_qubits_classes_qeff_temp, n_total_qubits_temp)])\n",
        "        measurements_results = (1./(self.epochs))*tc.backend.real(tf.stack([measurement_state[index_qubit_states[i], index_qubit_states[i]] for i in range(self.num_classes)]))\n",
        "        return measurements_results\n",
        "\n",
        "    def compile(\n",
        "            self,\n",
        "            optimizer=tf.keras.optimizers.legacy.Adam(0.0005), # originally 0.0005\n",
        "            **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to compile the model.\n",
        "\n",
        "        Args:\n",
        "            optimizer:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "        self.model.compile(\n",
        "            loss = \"categorical_crossentropy\",\n",
        "            optimizer=optimizer,\n",
        "            metrics=[\"accuracy\"],\n",
        "            **kwargs\n",
        "        )\n",
        "    def fit(self, x_train, y_train, batch_size=16, **kwargs):\n",
        " with         r\"\"\"\n",
        "        Method to fit (train) the model using the ad-hoc dataset.\n",
        "\n",
        "        Args:\n",
        "            x_train:\n",
        "            y_train:\n",
        "            batch_size:\n",
        "            epochs:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model.fit(x_train, y_train, batch_size=batch_size, epochs=self.epochs, **kwargs)\n",
        "\n",
        "    def predict(self, x_test):\n",
        "      r\"\"\"\n",
        "      Method to make predictions with the trained model.\n",
        "\n",
        "      Args:\n",
        "          x_test:\n",
        "\n",
        "      Returns:\n",
        "          The predictions of the conditional density estimation of the input data.\n",
        "      \"\"\"\n",
        "      return (tf.math.pow((self.gamma/(pi)), self.dim_lenet_out)*\\\n",
        "          self.model.predict(x_test)).numpy()"
      ],
      "metadata": {
        "id": "wx1iqwtc3C-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a LeNet CNN feature extraction model\n",
        "input_shape = X_train.shape[1:]\n",
        "INPUT_DIM = input_shape[0]\n",
        "N_QEFFS = 16\n",
        "NUM_CLASSES = 10\n",
        "DIM_LENET_OUT = 14 # originally 16\n",
        "GAMMA = 2**(0)\n",
        "EPOCHS = 10\n",
        "PURE_STATE_SIZE = 512\n",
        "\n",
        "weights_qeff_method = np.random.normal(size=(DIM_LENET_OUT, 2*(N_QEFFS-1)))/np.sqrt((N_QEFFS-1))\n",
        "\n",
        "weights_qeff_method.mean(), weights_qeff_method.std(), weights_qeff_method.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFztRGD85afk",
        "outputId": "694cc6a6-b63d-4c89-dd5f-48282ee06057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.002734544694931644, 0.2563007536159625, (14, 30))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qvkdc_lenet = QVKDC_MIXED_QEFF_LENET(qeff_weights_param = weights_qeff_method, num_classes_param = NUM_CLASSES, dim_lenet_out_param = DIM_LENET_OUT, input_dim_param = INPUT_DIM, var_pure_state_size=PURE_STATE_SIZE, gamma=GAMMA, epochs_param = EPOCHS)\n",
        "qvkdc_lenet.fit(X_train, y_train_oh, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyvsUziM6oBB",
        "outputId": "98ae66d2-2eec-464c-ee40-582abe512d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 1262s 382ms/step - loss: 2.4926 - accuracy: 0.2635\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 702s 374ms/step - loss: 1.4787 - accuracy: 0.4387\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 703s 375ms/step - loss: 1.1034 - accuracy: 0.6011\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 706s 377ms/step - loss: 0.7970 - accuracy: 0.7467\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 702s 374ms/step - loss: 0.6683 - accuracy: 0.7717\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 701s 374ms/step - loss: 0.5621 - accuracy: 0.7789\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 696s 371ms/step - loss: 0.4405 - accuracy: 0.8011\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 694s 370ms/step - loss: 0.4145 - accuracy: 0.8303\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 693s 370ms/step - loss: 0.3732 - accuracy: 0.8763\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 693s 370ms/step - loss: 0.2552 - accuracy: 0.8888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = qvkdc_lenet.predict(X_test)\n",
        "accuracy_score(y_test, np.argmax(y_pred, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kV2if6pw51Nc",
        "outputId": "edb19eef-a6e2-4d17-b04c-e127cbda86d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 450s 78ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8913"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FaPZL6XEwCGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 3: Mixed QMC variational, QEFF, with Le-Net Conv layer with HEA\n",
        "\n"
      ],
      "metadata": {
        "id": "RPhO5WuyXcYI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Libraries"
      ],
      "metadata": {
        "id": "qaX9L7h4Xqf7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d3581ae-f837-43ed-add3-db9a2a951c88",
        "id": "IueYuvibXqgG"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_logical_devices())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n",
            "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beeLYt7sXqgG"
      },
      "source": [
        "#### MNIST Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe0f1b10-6842-49a1-9a24-a18a3eb88a8b",
        "id": "C_tZgcvkXqgG"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train, X_test = X_train[..., np.newaxis]/255.0, X_test[..., np.newaxis]/255.0\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (10000, 28, 28, 1), (60000,), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea7ca900-dcd1-4ef3-ca2f-7926bf2bf3a5",
        "id": "e_SrsY_8XqgG"
      },
      "source": [
        "# Select the indices for the binary classification\n",
        "y_train = y_train[:, np.newaxis]\n",
        "y_test = y_test[:, np.newaxis]\n",
        "y_train_oh = tf.reshape (tf.keras.backend.one_hot(y_train, 10), (-1,10))\n",
        "y_test_oh = tf.reshape (tf.keras.backend.one_hot(y_test, 10), (-1,10))\n",
        "\n",
        "X_train.shape, X_test.shape, y_train_oh.shape, y_test_oh.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1),\n",
              " (10000, 28, 28, 1),\n",
              " TensorShape([60000, 10]),\n",
              " TensorShape([10000, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_logical_devices())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9480627-97de-44ee-80e0-b5a1a9febae6",
        "id": "aUD7v91zXqgH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n",
            "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of parameters of the Hardware efficient ansatz is given by,\n",
        "\n",
        "\n",
        "```\n",
        "HEA_size = n_qubits * (num_layers_hea + 1) * 2\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "7QwxuX2obHjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Quantum variational KDC with QEFF\n",
        "\n",
        "import tensorcircuit as tc\n",
        "from tensorcircuit import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import math as m\n",
        "from scipy.stats import entropy, spearmanr\n",
        "\n",
        "\n",
        "\n",
        "tc.set_backend(\"tensorflow\")\n",
        "tc.set_dtype(\"complex128\")\n",
        "\n",
        "pi = tf.constant(m.pi)\n",
        "\n",
        "\n",
        "class QVKDC_MIXED_QEFF_LENET_HEA:\n",
        "    r\"\"\"\n",
        "    Defines the ready-to-use Quantum measurement classification (QMC) model implemented\n",
        "    in TensorCircuit using the TensorFlow/Keras API. Any additional argument in the methods has to be Keras-compliant.\n",
        "\n",
        "    Args:\n",
        "        auto_compile: A boolean to autocompile the model using default settings. (Default True).\n",
        "        var_pure_state_size:\n",
        "        gamma:\n",
        "\n",
        "    Returns:\n",
        "        An instantiated model ready to train with ad-hoc data.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, qeff_weights_param, num_classes_param, input_dim_param, dim_lenet_out_param, auto_compile=True, var_hea_ansatz_size_param=64, num_layers_hea_param = 3, gamma=2., epochs_param=15):\n",
        "\n",
        "        self.circuit = None\n",
        "        self.gamma = gamma\n",
        "        self.num_classes = num_classes_param\n",
        "        self.num_layers_hea = num_layers_hea_param\n",
        "        self.var_hea_ansatz_size = var_hea_ansatz_size_param\n",
        "        self.qeff_weights_param =  qeff_weights_param\n",
        "        self.epochs = epochs_param\n",
        "        self.dim_lenet_out = dim_lenet_out_param\n",
        "\n",
        "        layer = keras.QuantumLayer(\n",
        "            partial(self.layer),\n",
        "            [(self.var_hea_ansatz_size,)]\n",
        "            )\n",
        "\n",
        "        ## build the Let-net model\n",
        "        self.model = Sequential()\n",
        "        self.model.add(tf.keras.layers.Conv2D(filters=20, kernel_size=(5, 5), padding=\"same\", activation='relu', input_shape=(input_dim_param, input_dim_param, 1)))\n",
        "        self.model.add(tf.keras.layers.AveragePooling2D())\n",
        "        self.model.add(tf.keras.layers.Conv2D(filters=50, kernel_size=(5, 5), padding=\"same\", activation='relu'))\n",
        "        self.model.add(tf.keras.layers.AveragePooling2D())\n",
        "        self.model.add(tf.keras.layers.Flatten())\n",
        "        self.model.add(tf.keras.layers.Dense(units=84, activation='relu'))\n",
        "        self.model.add(tf.keras.layers.Dense(units=self.dim_lenet_out, activation = 'relu')) # original \"softmax\"\n",
        "\n",
        "        # add the quantum layer\n",
        "\n",
        "        self.model.add(layer)\n",
        "        print(self.model.summary())\n",
        "\n",
        "        if auto_compile:\n",
        "            self.compile()\n",
        "\n",
        "    def layer(\n",
        "            self,\n",
        "            x_sample_param,\n",
        "            var_hea_ansatz_param,\n",
        "        ):\n",
        "        r\"\"\"\n",
        "        Defines a Density Matrix Kernel Density Estimation quantum layer for learning with fixed qaff (Meaning of qaff?). (This function was originally named dmkde_mixed_variational_density_estimation_fixed_qaff)\n",
        "\n",
        "        Args:\n",
        "            U_dagger:\n",
        "            var_pure_state_param:\n",
        "\n",
        "        Returns:\n",
        "            The probabilities of :math:`|k\\rangle`, `|1\\rangle`, ..., `|k\\rangle` state for kernel density classification of the classes.\n",
        "        \"\"\"\n",
        "\n",
        "        n_total_qubits_temp = int(self.var_hea_ansatz_size/((self.num_layers_hea+1)*2))\n",
        "        n_qeffs_temp = int((self.qeff_weights_param.shape[1] + 2)/2)\n",
        "        n_qubits_classes_qeff_temp = int(np.ceil(np.log2((self.num_classes))+np.ceil(np.log2((n_qeffs_temp)))))\n",
        "        n_qeff_qubits_temp = int(np.ceil(np.log2((n_qeffs_temp))))\n",
        "        n_classes_qubits_temp = int(np.ceil(np.log2(self.num_classes)))\n",
        "\n",
        "        #print(n_total_qubits_temp, n_qeffs_temp, n_qubits_classes_qeff_temp, n_qeff_qubits_temp, n_classes_qubits_temp)\n",
        "        ### iterators qeff, ps\n",
        "        index_iter_qeff = iter(np.arange(self.qeff_weights_param.shape[1]))\n",
        "        index_iter_hea  = iter(np.arange(len(var_hea_ansatz_param)))\n",
        "\n",
        "        ### indices classes, of ms\n",
        "        index_qubit_states = indices_qubits_clases(n_qubits_classes_qeff_temp, self.num_classes) # extract indices of the bit string of classes\n",
        "\n",
        "        # Instantiate a circuit with the calculated number of qubits.\n",
        "        self.circuit = tc.Circuit(n_total_qubits_temp)\n",
        "\n",
        "        def hea_ansatz(qc_param, num_qubits_param, num_layers_param):\n",
        "        # encoding\n",
        "          for i in range (0, num_qubits_param):\n",
        "            qc_param.ry(i, theta = var_hea_ansatz_param[next(index_iter_hea)])\n",
        "            qc_param.rz(i, theta = var_hea_ansatz_param[next(index_iter_hea)])\n",
        "        # layers\n",
        "          for j in range(num_layers_param):\n",
        "            for i in range (0, num_qubits_param-1):\n",
        "              qc_param.CNOT(i, i+1)\n",
        "\n",
        "            for i in range (0, num_qubits_param):\n",
        "              qc_param.ry(i, theta= var_hea_ansatz_param[next(index_iter_hea)])\n",
        "              qc_param.rz(i, theta= var_hea_ansatz_param[next(index_iter_hea)])\n",
        "\n",
        "        ## learning pure state with HEA\n",
        "\n",
        "        hea_ansatz(self.circuit, n_total_qubits_temp, self.num_layers_hea)\n",
        "\n",
        "        # Value to predict\n",
        "\n",
        "        x_sample_temp = tf.expand_dims(x_sample_param, axis=0)\n",
        "        phases_temp = tf.sqrt(tf.cast(self.gamma, tf.float64))*tf.linalg.matmul(tf.cast(x_sample_temp, tf.float64), self.qeff_weights_param)\n",
        "        init_qubit_qeff_temp = n_classes_qubits_temp # qubit at which the qaff mapping starts it starts after the qubits of the classes\n",
        "\n",
        "        def circuit_base_rz_qeff_n(qc_param, num_qubits_param, target_qubit_param, init_qubit_param):\n",
        "          if num_qubits_param == 1:\n",
        "            qc_param.rz(init_qubit_param, theta = phases_temp[0][next(index_iter_qeff)])\n",
        "            qc_param.X(init_qubit_param)\n",
        "            qc_param.rz(init_qubit_param, theta = phases_temp[0][next(index_iter_qeff)])\n",
        "          elif num_qubits_param == 2:\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[0][next(index_iter_qeff)])\n",
        "            qc_param.X(target_qubit_param + init_qubit_param)\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[0][next(index_iter_qeff)])\n",
        "            qc_param.cnot(init_qubit_param, target_qubit_param + init_qubit_param)\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[0][next(index_iter_qeff)])\n",
        "            qc_param.X(target_qubit_param + init_qubit_param)\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[0][next(index_iter_qeff)])\n",
        "            return\n",
        "          else:\n",
        "            circuit_base_rz_qeff_n(qc_param, num_qubits_param-1, target_qubit_param, init_qubit_param)\n",
        "            qc_param.cnot(num_qubits_param-2+init_qubit_param, target_qubit_param+init_qubit_param)\n",
        "            circuit_base_rz_qeff_n(qc_param, num_qubits_param-1, target_qubit_param, init_qubit_param)\n",
        "            target_qubit_param -= 1\n",
        "\n",
        "        # Applying the QEFF feature map\n",
        "\n",
        "        for i in range(n_qubits_classes_qeff_temp - init_qubit_qeff_temp + 1 - 1, 1 - 1, -1):\n",
        "          circuit_base_rz_qeff_n(self.circuit, i, i - 1, init_qubit_qeff_temp)\n",
        "\n",
        "        for i in range(init_qubit_qeff_temp, n_qubits_classes_qeff_temp):\n",
        "          self.circuit.H(i)\n",
        "\n",
        "        # Trace out ancilla qubits, find probability of |k> state for the prediction of class k\n",
        "\n",
        "        measurement_state = tc.quantum.reduced_density_matrix(self.circuit.state(), cut=[m for m in range(n_qubits_classes_qeff_temp, n_total_qubits_temp)])\n",
        "        measurements_results = (1./(self.epochs))*tc.backend.real(tf.stack([measurement_state[index_qubit_states[i], index_qubit_states[i]] for i in range(self.num_classes)]))\n",
        "        return measurements_results\n",
        "\n",
        "    def compile(\n",
        "            self,\n",
        "            optimizer=tf.keras.optimizers.legacy.Adam(0.0005), # originally 0.0005\n",
        "            **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to compile the model.\n",
        "\n",
        "        Args:\n",
        "            optimizer:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "        self.model.compile(\n",
        "            loss = \"categorical_crossentropy\",\n",
        "            optimizer=optimizer,\n",
        "            metrics=[\"accuracy\"],\n",
        "            **kwargs\n",
        "        )\n",
        "    def fit(self, x_train, y_train, batch_size=16, **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to fit (train) the model using the ad-hoc dataset.\n",
        "\n",
        "        Args:\n",
        "            x_train:\n",
        "            y_train:\n",
        "            batch_size:\n",
        "            epochs:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model.fit(x_train, y_train, batch_size=batch_size, epochs=self.epochs, **kwargs)\n",
        "\n",
        "    def predict(self, x_test):\n",
        "      r\"\"\"\n",
        "      Method to make predictions with the trained model.\n",
        "\n",
        "      Args:\n",
        "          x_test:\n",
        "\n",
        "      Returns:\n",
        "          The predictions of the conditional density estimation of the input data.\n",
        "      \"\"\"\n",
        "      return (tf.math.pow((self.gamma/(pi)), self.dim_lenet_out/2)*\\\n",
        "          self.model.predict(x_test)).numpy()"
      ],
      "metadata": {
        "id": "VSF5BojeXqgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a LeNet CNN feature extraction model\n",
        "input_shape = X_train.shape[1:]\n",
        "INPUT_DIM = input_shape[0]\n",
        "N_QEFFS = 16\n",
        "NUM_CLASSES = 10\n",
        "DIM_LENET_OUT = 14 # originally 16\n",
        "GAMMA = 2**(0)\n",
        "EPOCHS = 10\n",
        "NUM_LAYERS_HEA = 3\n",
        "NUM_ANCILLA_QUBITS = 1\n",
        "NUM_TOTAL_QUBITS = int(np.ceil(np.log2(NUM_CLASSES)) + np.ceil(np.log2(N_QEFFS)) + NUM_ANCILLA_QUBITS)\n",
        "HEA_ANSATZ_SIZE = int(NUM_TOTAL_QUBITS*(NUM_LAYERS_HEA+1)*2)\n",
        "\n",
        "weights_qeff_method = np.random.normal(size=(DIM_LENET_OUT, 2*(N_QEFFS-1)))/np.sqrt((N_QEFFS-1))\n",
        "\n",
        "weights_qeff_method.mean(), weights_qeff_method.std(), weights_qeff_method.shape, HEA_ANSATZ_SIZE, NUM_TOTAL_QUBITS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "347615c4-4d60-457f-a5a5-ff4527e04678",
        "id": "LGqAK7bhXqgH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0011090572287938744, 0.2598442347195675, (14, 30), 72, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qvkdc_hea_lenet = QVKDC_MIXED_QEFF_LENET_HEA(qeff_weights_param = weights_qeff_method, num_classes_param = NUM_CLASSES, dim_lenet_out_param = DIM_LENET_OUT, input_dim_param = INPUT_DIM, var_hea_ansatz_size_param = HEA_ANSATZ_SIZE, num_layers_hea_param = NUM_LAYERS_HEA, gamma=GAMMA, epochs_param = EPOCHS)\n",
        "qvkdc_hea_lenet.fit(X_train, y_train_oh, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "outputId": "a28c99a2-eae7-46b3-b0a3-4de3ce2b7756",
        "id": "_nW0e3JoXqgH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 20)        520       \n",
            "                                                                 \n",
            " average_pooling2d_8 (Avera  (None, 14, 14, 20)        0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 14, 14, 50)        25050     \n",
            "                                                                 \n",
            " average_pooling2d_9 (Avera  (None, 7, 7, 50)          0         \n",
            " gePooling2D)                                                    \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 2450)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 84)                205884    \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 14)                1190      \n",
            "                                                                 \n",
            " quantum_layer_4 (QuantumLa  (None, 10)                72        \n",
            " yer)                                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 232716 (909.33 KB)\n",
            "Trainable params: 232716 (909.33 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Concurrent access?",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-fe829d40a69b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mqvkdc_hea_lenet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQVKDC_MIXED_QEFF_LENET_HEA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqeff_weights_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights_qeff_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_lenet_out_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDIM_LENET_OUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mINPUT_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_hea_ansatz_size_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHEA_ANSATZ_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers_hea_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNUM_LAYERS_HEA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGAMMA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mqvkdc_hea_lenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_oh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-ce98dfd092a5>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \"\"\"\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/tf_stack.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_traceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stack_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Concurrent access?'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Concurrent access?"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = qvkdc_hea_lenet.predict(X_test)\n",
        "accuracy_score(y_test, np.argmax(y_pred, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f778ee-26d3-44fc-af5e-0060bb2a3599",
        "id": "km5HWHinXqgH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 16 8 4 4\n",
            "313/313 [==============================] - 37s 37ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9902"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}