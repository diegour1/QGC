{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7VwQfaCOcok"
      },
      "source": [
        "## Quantum Measurement Classification with Mixed States on Ten Classes MNIST with quantum-enhanced Fourier features\n",
        "\n",
        "Diego Useche"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px6NXiW6Q74M"
      },
      "source": [
        "## GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al0mmMn7Q9oM",
        "outputId": "16a0c26e-6343-4aa1-f79d-d45c2f410b6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPeuojM4RUB1"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5IafHoCOqgN",
        "outputId": "e16e6045-135b-4562-f215-3c7a5daa83bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorcircuit\n",
            "  Downloading tensorcircuit-0.12.0-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorcircuit) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from tensorcircuit) (1.13.1)\n",
            "Collecting tensornetwork-ng (from tensorcircuit)\n",
            "  Downloading tensornetwork_ng-0.5.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from tensorcircuit) (3.4.2)\n",
            "Requirement already satisfied: graphviz>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from tensornetwork-ng->tensorcircuit) (0.20.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from tensornetwork-ng->tensorcircuit) (3.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensornetwork-ng->tensorcircuit) (3.12.1)\n",
            "Downloading tensorcircuit-0.12.0-py3-none-any.whl (342 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.0/342.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensornetwork_ng-0.5.0-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensornetwork-ng, tensorcircuit\n",
            "Successfully installed tensorcircuit-0.12.0 tensornetwork-ng-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorcircuit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15DqVUX2Ocop",
        "outputId": "f3a11bcb-36d8-4eb9-8693-f01e1ba475d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorcircuit.translation:Please first ``pip install -U qiskit`` to enable related functionality in translation module\n",
            "WARNING:tensorcircuit.translation:Please first ``pip install -U cirq`` to enable related functionality in translation module\n"
          ]
        }
      ],
      "source": [
        "from functools import partial\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorcircuit as tc\n",
        "from tensorcircuit import keras\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzQg29OoOcos",
        "outputId": "a52bfb13-6935-4fb1-f2d6-ba9671a87d00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('complex128', 'float64')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "tc.set_backend(\"tensorflow\")\n",
        "tc.set_dtype(\"complex128\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P856730WaRBB",
        "outputId": "183b1c4e-bf98-48fc-df7e-6e926ac0c306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n",
            "[LogicalDevice(name='/device:CPU:0', device_type='CPU')]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(tf.__version__)\n",
        "print(tf.config.list_logical_devices())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHUQ385IUKo4"
      },
      "source": [
        "## Utils functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcxPN_lIUNI0",
        "outputId": "55f25b11-afcd-4e1f-9895-6e5e38d9f587"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 4, 8, 12]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# this function takes the number of classes and of qubits of the qmc pure, and extract the indices\n",
        "# of the bit strings that correpond to the classes prediction\n",
        "## Example, qmc prediction bit string [\"00\", \"01\", \"10\", \"11\"]\n",
        "## the classes prediction is encoded in [\"00\", \"10\"], then it returns [0, 2]\n",
        "\n",
        "def _indices_qubits_classes(num_qubits_param, num_classes_param):\n",
        "  num_qubits_classes_temp = int(np.ceil(np.log2(num_classes_param)))\n",
        "  a = [np.binary_repr(i, num_qubits_param) for i in range(2**num_qubits_param)]\n",
        "  b = [(np.binary_repr(i, num_qubits_classes_temp) + \"0\"*(num_qubits_param - num_qubits_classes_temp)) for i in range(num_classes_param)]\n",
        "  indices_temp = []\n",
        "  for i in range(len(a)):\n",
        "    if a[i] in b:\n",
        "      indices_temp.append(i)\n",
        "\n",
        "  return indices_temp\n",
        "\n",
        "_indices_qubits_classes(4, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9OHBspfbc5Z"
      },
      "source": [
        "## MNIST Data Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU2-64qJaRBC",
        "outputId": "3cf23a9b-e660-4e0b-83c6-c8bc15413f8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (10000, 28, 28, 1), (60000,), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train, X_test = X_train[..., np.newaxis]/255.0, X_test[..., np.newaxis]/255.0\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1aMky5qaRBC",
        "outputId": "a5791ec8-90ee-425c-e5f6-bf1df3e73c7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1),\n",
              " (10000, 28, 28, 1),\n",
              " TensorShape([60000, 10]),\n",
              " TensorShape([10000, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Select the indices for the binary classification\n",
        "y_train = y_train[:, np.newaxis]\n",
        "y_test = y_test[:, np.newaxis]\n",
        "y_train_oh = tf.reshape (tf.keras.backend.one_hot(y_train, 10), (-1,10))\n",
        "y_test_oh = tf.reshape (tf.keras.backend.one_hot(y_test, 10), (-1,10))\n",
        "\n",
        "X_train.shape, X_test.shape, y_train_oh.shape, y_test_oh.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 1: Mixed QMC variational, QEFF, with Le-Net Conv layer with APA, Discriminative then generative learning"
      ],
      "metadata": {
        "id": "WyEEfih9EvOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Quantum variational KDC with QEFF\n",
        "\n",
        "import tensorcircuit as tc\n",
        "from tensorcircuit import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import math as m\n",
        "from scipy.stats import entropy, spearmanr\n",
        "\n",
        "tc.set_backend(\"tensorflow\")\n",
        "tc.set_dtype(\"complex128\")\n",
        "\n",
        "pi = tf.constant(m.pi)\n",
        "class VQKDC_MIXED_QEFF_LENET:\n",
        "    r\"\"\"\n",
        "    Defines the ready-to-use Quantum measurement classification (QMC) model implemented\n",
        "    in TensorCircuit using the TensorFlow/Keras API. Any additional argument in the methods has to be Keras-compliant.\n",
        "\n",
        "    Args:\n",
        "        auto_compile: A boolean to autocompile the model using default settings. (Default True).\n",
        "        var_pure_state_size:\n",
        "        gamma:\n",
        "\n",
        "    Returns:\n",
        "        An instantiated model ready to train with ad-hoc data.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, n_qeff_qubits, n_ancilla_qubits, num_classes_qubits, num_classes_param, dim_lenet_out_param, input_dim_param, gamma, n_training_data,  reduction = \"none\", training_type = \"generative\", batch_size = 16, learning_rate = 0.0005, random_state = 15, auto_compile=True):\n",
        "\n",
        "        self.circuit = None\n",
        "        self.gamma = gamma\n",
        "        self.num_classes = num_classes_param\n",
        "        self.num_classes_qubits = num_classes_qubits\n",
        "        self.n_qeff_qubits = n_qeff_qubits\n",
        "        self.n_ancilla_qubits = n_ancilla_qubits\n",
        "        self.n_total_qubits_temp = self.num_classes_qubits + self.n_qeff_qubits + self.n_ancilla_qubits\n",
        "        self.num_ffs = 2**self.n_qeff_qubits\n",
        "        self.n_training_data = n_training_data\n",
        "        self.dim_lenet_out = dim_lenet_out_param\n",
        "        self.input_dim = input_dim_param\n",
        "        self.var_pure_state_parameters_size = 2*(2**self.n_total_qubits_temp - 1)\n",
        "        self.reduction  = reduction\n",
        "        self.training_type = training_type\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.qeff_weights = tf.random.normal((self.dim_lenet_out, int(self.num_ffs*1-1)), mean = 0.0, stddev = 2.0/np.sqrt(self.num_ffs - 1), dtype=tf.dtypes.float64, seed = random_state)\n",
        "\n",
        "        layer = keras.QuantumLayer(\n",
        "            partial(self.layer),\n",
        "            [(self.var_pure_state_parameters_size,)]\n",
        "            )\n",
        "\n",
        "        ## build the Let-net model\n",
        "        self.model = Sequential()\n",
        "        self.model.add(tf.keras.layers.Conv2D(filters=20, kernel_size=(5, 5), padding=\"same\", activation='relu', input_shape=(self.input_dim, self.input_dim, 1)))\n",
        "        self.model.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2))\n",
        "        self.model.add(tf.keras.layers.Conv2D(filters=50, kernel_size=(5, 5), padding=\"same\", activation='relu'))\n",
        "        self.model.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2))\n",
        "        self.model.add(tf.keras.layers.Flatten())\n",
        "        self.model.add(tf.keras.layers.Dense(units=84, activation='relu'))\n",
        "        self.model.add(tf.keras.layers.Dense(units=self.dim_lenet_out, activation = None)) # original \"softmax\"\n",
        "\n",
        "        # add the quantum layer\n",
        "\n",
        "        self.model.add(layer)\n",
        "        print(self.model.summary())\n",
        "\n",
        "        if auto_compile:\n",
        "            self.compile()\n",
        "\n",
        "    def layer(\n",
        "            self,\n",
        "            x_sample_param,\n",
        "            var_pure_state_param,\n",
        "        ):\n",
        "        r\"\"\"\n",
        "        Defines a Density Matrix Kernel Density Estimation quantum layer for learning with fixed qaff (Meaning of qaff?). (This function was originally named dmkde_mixed_variational_density_estimation_fixed_qaff)\n",
        "\n",
        "        Args:\n",
        "            U_dagger:\n",
        "            var_pure_state_param:\n",
        "\n",
        "        Returns:\n",
        "            The probabilities of :math:`|k\\rangle`, `|1\\rangle`, ..., `|k\\rangle` state for kernel density classification of the classes.\n",
        "        \"\"\"\n",
        "\n",
        "        ### indices pure state\n",
        "        index_it = iter(np.arange(len(var_pure_state_param)))\n",
        "\n",
        "        ### indices qeff\n",
        "        index_iter_qeff = iter(np.arange(self.qeff_weights.shape[1]))\n",
        "\n",
        "        ### indices classes, of ms\n",
        "        n_qubits_classes_qeff_temp = self.num_classes_qubits + self.n_qeff_qubits\n",
        "        index_qubit_states = _indices_qubits_classes(n_qubits_classes_qeff_temp, self.num_classes) # extract indices of the bit string of classes\n",
        "\n",
        "\n",
        "        # Instantiate a circuit with the calculated number of qubits.\n",
        "        self.circuit = tc.Circuit(self.n_total_qubits_temp)\n",
        "\n",
        "        def circuit_base_ry_n(qc_param, num_qubits_param, target_qubit_param):\n",
        "            if num_qubits_param == 1:\n",
        "                qc_param.ry(0, theta = var_pure_state_param[next(index_it)])\n",
        "            elif num_qubits_param == 2:\n",
        "                qc_param.ry(target_qubit_param, theta=var_pure_state_param[next(index_it)])\n",
        "                qc_param.cnot(0, target_qubit_param)\n",
        "                qc_param.ry(target_qubit_param, theta=var_pure_state_param[next(index_it)])\n",
        "                return\n",
        "            else:\n",
        "                circuit_base_ry_n(qc_param, num_qubits_param-1, target_qubit_param)\n",
        "                qc_param.cnot(num_qubits_param-2, target_qubit_param)\n",
        "                circuit_base_ry_n(qc_param, num_qubits_param-1, target_qubit_param)\n",
        "                target_qubit_param -= 1\n",
        "\n",
        "        def circuit_base_rz_n(qc_param, num_qubits_param, target_qubit_param):\n",
        "            if num_qubits_param == 1:\n",
        "                qc_param.rz(0, theta = var_pure_state_param[next(index_it)])\n",
        "            elif num_qubits_param == 2:\n",
        "                qc_param.rz(target_qubit_param, theta=var_pure_state_param[next(index_it)])\n",
        "                qc_param.cnot(0, target_qubit_param)\n",
        "                qc_param.rz(target_qubit_param, theta=var_pure_state_param[next(index_it)])\n",
        "                return\n",
        "            else:\n",
        "                circuit_base_rz_n(qc_param, num_qubits_param-1, target_qubit_param)\n",
        "                qc_param.cnot(num_qubits_param-2, target_qubit_param)\n",
        "                circuit_base_rz_n(qc_param, num_qubits_param-1, target_qubit_param)\n",
        "                target_qubit_param -= 1\n",
        "\n",
        "        # Learning pure state\n",
        "        for i in range(1, self.n_total_qubits_temp+1):\n",
        "            circuit_base_ry_n(self.circuit, i, i-1)\n",
        "\n",
        "        # Learning pure state complex phase\n",
        "        for j in range(1, self.n_total_qubits_temp+1):\n",
        "            circuit_base_rz_n(self.circuit, j, j-1)\n",
        "\n",
        "        # Value to predict\n",
        "\n",
        "        x_sample_temp = tf.expand_dims(x_sample_param, axis=0)\n",
        "        phases_temp = (tf.cast(tf.sqrt(self.gamma), tf.float64)*tf.linalg.matmul(tf.cast(x_sample_temp, tf.float64), self.qeff_weights))[0]\n",
        "        init_qubit_qeff_temp = self.num_classes_qubits # qubit at which the qaff mapping starts it starts after the qubits of the classes\n",
        "\n",
        "        def circuit_base_rz_qeff_n(qc_param, num_qubits_param, target_qubit_param, init_qubit_param):\n",
        "          if num_qubits_param == 1:\n",
        "            qc_param.rz(init_qubit_param, theta = phases_temp[next(index_iter_qeff)] )\n",
        "          elif num_qubits_param == 2:\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[next(index_iter_qeff)])\n",
        "            qc_param.cnot(init_qubit_param, target_qubit_param + init_qubit_param)\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[next(index_iter_qeff)])\n",
        "            return\n",
        "          else:\n",
        "            circuit_base_rz_qeff_n(qc_param, num_qubits_param-1, target_qubit_param, init_qubit_param)\n",
        "            qc_param.cnot(num_qubits_param-2 + init_qubit_param, target_qubit_param + init_qubit_param)\n",
        "            circuit_base_rz_qeff_n(qc_param, num_qubits_param-1, target_qubit_param, init_qubit_param)\n",
        "            target_qubit_param -= 1\n",
        "\n",
        "        # Applying the QEFF feature map\n",
        "\n",
        "        for i in reversed(range(1, self.n_qeff_qubits + 1)):\n",
        "          circuit_base_rz_qeff_n(self.circuit, i, i - 1, init_qubit_qeff_temp)\n",
        "\n",
        "        for i in range(init_qubit_qeff_temp, init_qubit_qeff_temp + self.n_qeff_qubits):\n",
        "          self.circuit.H(i)\n",
        "\n",
        "        # Trace out ancilla qubits, find probability of [000] state for density estimation\n",
        "        measurement_state = tc.quantum.reduced_density_matrix(\n",
        "                        self.circuit.state(),\n",
        "                        cut=[m for m in range(n_qubits_classes_qeff_temp, self.n_total_qubits_temp)])\n",
        "        measurements_results = tc.backend.real(tf.stack([measurement_state[index_qubit_states[i], index_qubit_states[i]] for i in range(self.num_classes)]))\n",
        "        if self.training_type == \"discriminative\":\n",
        "          measurements_results = measurements_results / tf.reduce_sum(measurements_results, axis = -1)\n",
        "        print(self.training_type)\n",
        "        return measurements_results\n",
        "\n",
        "    def custom_categorical_crossentropy(self, y_true, y_pred):\n",
        "      ## code generated with the aid of chat gpt\n",
        "      \"\"\"\n",
        "      Compute the categorical cross-entropy loss with mean reduction.\n",
        "\n",
        "      Args:\n",
        "      y_true: Tensor of true labels, shape (batch_size, num_classes).\n",
        "      y_pred: Tensor of predicted probabilities, shape (batch_size, num_classes).\n",
        "\n",
        "      Returns:\n",
        "      Scalar tensor representing the mean loss over the batch.\n",
        "      \"\"\"\n",
        "      # Ensure predictions are clipped to avoid log(0)\n",
        "      epsilon_two = 1e-7  # small constant to avoid division by zero\n",
        "      y_pred = tf.clip_by_value(y_pred, epsilon_two, np.inf)  # clip values to avoid log(0) originaly 1.0 - epsilon\n",
        "\n",
        "      # Compute the categorical cross-entropy loss for each sample\n",
        "      loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
        "\n",
        "      if self.reduction == \"none\":\n",
        "        return loss\n",
        "      elif self.reduction == \"mean\":\n",
        "        # Compute the mean loss over the batch\n",
        "        mean_loss = tf.reduce_mean(loss)\n",
        "        return mean_loss\n",
        "      elif self.reduction == \"sum\":\n",
        "        # Compute the sum loss over the batch\n",
        "        sum_loss = tf.reduce_sum(loss)\n",
        "        return sum_loss\n",
        "      else:\n",
        "        return loss\n",
        "\n",
        "    def compile(\n",
        "            self,\n",
        "            optimizer=tf.keras.optimizers.Adam,\n",
        "            **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to compile the model.\n",
        "\n",
        "        Args:\n",
        "            optimizer:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "        self.model.compile(\n",
        "            loss = self.custom_categorical_crossentropy,\n",
        "            optimizer=optimizer(self.learning_rate),\n",
        "            metrics=[\"accuracy\"],\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "    def fit(self, x_train, y_train, batch_size=16, epochs = 30, **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to fit (train) the model using the ad-hoc dataset.\n",
        "\n",
        "        Args:\n",
        "            x_train:\n",
        "            y_train:\n",
        "            batch_size:\n",
        "            epochs:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model.fit(x_train, y_train, batch_size = self.batch_size, epochs = epochs, **kwargs)\n",
        "\n",
        "    def predict(self, x_test):\n",
        "      r\"\"\"\n",
        "      Method to make predictions with the trained model.\n",
        "\n",
        "      Args:\n",
        "          x_test:\n",
        "\n",
        "      Returns:\n",
        "          The predictions of the conditional density estimation of the input data.\n",
        "      \"\"\"\n",
        "      return (tf.experimental.numpy.power((self.gamma/(pi)), self.dim_lenet_out/2.)*\\\n",
        "          self.model.predict(x_test)).numpy()\n",
        "\n",
        "    def extract_lenet_features(self, x_test):\n",
        "      r\"\"\"\n",
        "      Method to extract the features of the Lenet.\n",
        "\n",
        "      Args:\n",
        "          x_test:\n",
        "\n",
        "      Returns:\n",
        "          Features of the Lenet.\n",
        "      \"\"\"\n",
        "      extract = Model(self.model.inputs, self.model.layers[-2].output)\n",
        "      new_model = Sequential()\n",
        "      new_model.add(extract)\n",
        "      return new_model.predict(x_test)\n",
        "\n",
        "    def freeze_lenet(self):\n",
        "      r\"\"\"\n",
        "      Method to frezze the layers of the Lenet.\n",
        "\n",
        "      Args:\n",
        "          self:\n",
        "\n",
        "      Returns:\n",
        "          None.\n",
        "      \"\"\"\n",
        "      for layer in self.model.layers[:-1]:\n",
        "          layer.trainable = False\n",
        "\n",
        "    def set_training_type(self, new_training_type):\n",
        "      r\"\"\"\n",
        "      Method to change the training type of the method during training.\n",
        "\n",
        "      Args:\n",
        "          new_training_strategy:\n",
        "\n",
        "      Returns:\n",
        "          None.\n",
        "      \"\"\"\n",
        "      self.training_type = new_training_type"
      ],
      "metadata": {
        "id": "UZDEPKZYFA1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtcjfrqOJF5Y"
      },
      "outputs": [],
      "source": [
        "## training the quantum circuit\n",
        "# Define a LeNet CNN feature extraction model\n",
        "input_shape = X_train.shape[1:]\n",
        "INPUT_DIM = input_shape[0]\n",
        "NUM_QUBITS_FFS = 4 ## originally N_QEFFS = 16\n",
        "NUM_CLASSES = 10\n",
        "NUM_CLASSES_QUBITS = 4\n",
        "DIM_LENET_OUT = 30 # originally 16\n",
        "GAMMA = 2**(-2) ## originally 2**(0)\n",
        "EPOCHS = 5\n",
        "N_TRAINING_DATA = X_train.shape[0]\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 0.0005 ## originally 0.0005\n",
        "RANDOM_STATE_QEFF = 123\n",
        "NUM_ANCILLA_QUBITS = 1\n",
        "NUM_TOTAL_QUBITS = NUM_QUBITS_FFS + NUM_ANCILLA_QUBITS + NUM_CLASSES_QUBITS\n",
        "TRAINING_TYPE = \"generative\"\n",
        "REDUCTION = \"none\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## this code creates a discriminative model\n",
        "vqkdc = VQKDC_MIXED_QEFF_LENET(n_qeff_qubits = NUM_QUBITS_FFS, n_ancilla_qubits =  NUM_ANCILLA_QUBITS, num_classes_qubits = NUM_CLASSES_QUBITS, num_classes_param = NUM_CLASSES, dim_lenet_out_param = DIM_LENET_OUT, input_dim_param = INPUT_DIM, gamma=GAMMA, n_training_data = N_TRAINING_DATA,  reduction = REDUCTION, training_type = TRAINING_TYPE, batch_size = BATCH_SIZE, learning_rate = LEARNING_RATE, random_state = RANDOM_STATE_QEFF, auto_compile = False)\n",
        "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
        "vqkdc.model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "vqkdc.fit(X_train, y_train_oh, epochs = EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "RdqmWw1ASVHZ",
        "outputId": "267d3b01-1c4a-4d7b-dcd7-c5fef4590eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generative\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,050</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_1                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2450</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">205,884</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ quantum_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">QuantumLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,022</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │             \u001b[38;5;34m520\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d (\u001b[38;5;33mAveragePooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │          \u001b[38;5;34m25,050\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_1                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2450\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)                  │         \u001b[38;5;34m205,884\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │           \u001b[38;5;34m2,550\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ quantum_layer (\u001b[38;5;33mQuantumLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,022\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,026</span> (922.06 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,026\u001b[0m (922.06 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,026</span> (922.06 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,026\u001b[0m (922.06 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/5\n",
            "generative\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1447s\u001b[0m 225ms/step - accuracy: 0.2856 - loss: 3.1587\n",
            "Epoch 2/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m900s\u001b[0m 240ms/step - accuracy: 0.6092 - loss: 0.9907\n",
            "Epoch 3/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m996s\u001b[0m 260ms/step - accuracy: 0.8978 - loss: 0.3020\n",
            "Epoch 4/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m926s\u001b[0m 245ms/step - accuracy: 0.9812 - loss: 0.1097\n",
            "Epoch 5/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m888s\u001b[0m 236ms/step - accuracy: 0.9860 - loss: 0.0682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this code frezzes the weights of the Le net layer, and then sets the model to be trained in a generative way\n",
        "for layer in vqkdc.model.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "vqkdc.compile()\n",
        "vqkdc.fit(X_train, y_train_oh, epochs = EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAtO5lUhInuA",
        "outputId": "c2ee6426-49af-4c69-f800-4ccfe8c406f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m951s\u001b[0m 227ms/step - accuracy: 0.9178 - loss: 2.9227\n",
            "Epoch 2/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m829s\u001b[0m 218ms/step - accuracy: 0.9845 - loss: 2.3402\n",
            "Epoch 3/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m827s\u001b[0m 220ms/step - accuracy: 0.9840 - loss: 2.3409\n",
            "Epoch 4/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m917s\u001b[0m 235ms/step - accuracy: 0.9841 - loss: 2.3403\n",
            "Epoch 5/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m882s\u001b[0m 235ms/step - accuracy: 0.9844 - loss: 2.3400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = vqkdc.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test, np.argmax(y_pred, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhLW8egpL7e8",
        "outputId": "df6c3289-1b2d-474e-f8fb-08bf8925f6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generative\n",
            "\u001b[1m312/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/stepgenerative\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m940s\u001b[0m 2s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9821"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 2: Mixed QMC variational, QEFF, with Le-Net Conv layer with HEA, Discriminative then generative learning"
      ],
      "metadata": {
        "id": "rhA_MdBcAxsM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjsJO7YGAxsN"
      },
      "source": [
        "The number of parameters of the Hardware efficient ansatz is given by,\n",
        "\n",
        "\n",
        "```\n",
        "HEA_size = n_qubits * (num_layers_hea + 1) * 2\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Quantum variational KDC with QEFF\n",
        "\n",
        "import tensorcircuit as tc\n",
        "from tensorcircuit import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import math as m\n",
        "from scipy.stats import entropy, spearmanr\n",
        "\n",
        "tc.set_backend(\"tensorflow\")\n",
        "tc.set_dtype(\"complex128\")\n",
        "\n",
        "pi = tf.constant(m.pi)\n",
        "\n",
        "class VQKDC_MIXED_QEFF_HEA_LENET:\n",
        "    r\"\"\"\n",
        "    Defines the ready-to-use Quantum measurement classification (QMC) model implemented\n",
        "    in TensorCircuit using the TensorFlow/Keras API. Any additional argument in the methods has to be Keras-compliant.\n",
        "\n",
        "    Args:\n",
        "        auto_compile: A boolean to autocompile the model using default settings. (Default True).\n",
        "        var_pure_state_size:\n",
        "        gamma:\n",
        "\n",
        "    Returns:\n",
        "        An instantiated model ready to train with ad-hoc data.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, n_qeff_qubits, n_ancilla_qubits, num_classes_qubits, num_classes_param, dim_lenet_out_param,  input_dim_param, gamma, n_training_data, reduction = \"none\", training_type = \"generative\", num_layers_hea = 3, batch_size = 16, learning_rate = 0.0005, random_state = 15, auto_compile=True):\n",
        "\n",
        "        self.circuit = None\n",
        "        self.gamma = gamma\n",
        "        self.num_layers_hea = num_layers_hea\n",
        "        self.num_classes = num_classes_param\n",
        "        self.num_classes_qubits = num_classes_qubits\n",
        "        self.n_qeff_qubits = n_qeff_qubits\n",
        "        self.n_ancilla_qubits = n_ancilla_qubits\n",
        "        self.n_total_qubits_temp = self.num_classes_qubits + self.n_qeff_qubits + self.n_ancilla_qubits\n",
        "        self.num_ffs = 2**self.n_qeff_qubits\n",
        "        self.n_training_data = n_training_data\n",
        "        self.dim_lenet_out = dim_lenet_out_param\n",
        "        self.input_dim = input_dim_param\n",
        "        self.var_hea_ansatz_size = int(self.n_total_qubits_temp*(self.num_layers_hea+1)*2)\n",
        "        self.reduction  = reduction\n",
        "        self.training_type = training_type\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "        self.qeff_weights = tf.random.normal((self.dim_lenet_out, int(self.num_ffs*1-1)), mean = 0.0, stddev = 2.0/np.sqrt(self.num_ffs - 1), dtype=tf.dtypes.float64, seed = random_state)\n",
        "\n",
        "        layer = keras.QuantumLayer(\n",
        "            partial(self.layer),\n",
        "            [(self.var_hea_ansatz_size,)]\n",
        "            )\n",
        "\n",
        "        ## build the Let-net model\n",
        "        self.model = Sequential()\n",
        "        self.model.add(tf.keras.layers.Conv2D(filters=20, kernel_size=(5, 5), padding=\"same\", activation='relu', input_shape=(self.input_dim, self.input_dim, 1)))\n",
        "        self.model.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2))\n",
        "        self.model.add(tf.keras.layers.Conv2D(filters=50, kernel_size=(5, 5), padding=\"same\", activation='relu'))\n",
        "        self.model.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2))\n",
        "        self.model.add(tf.keras.layers.Flatten())\n",
        "        self.model.add(tf.keras.layers.Dense(units=84, activation='relu'))\n",
        "        self.model.add(tf.keras.layers.Dense(units=self.dim_lenet_out, activation = None)) # original \"softmax\"\n",
        "\n",
        "        # add the quantum layer\n",
        "\n",
        "        self.model.add(layer)\n",
        "        print(self.model.summary())\n",
        "\n",
        "        if auto_compile:\n",
        "            self.compile()\n",
        "\n",
        "    def layer(\n",
        "            self,\n",
        "            x_sample_param,\n",
        "            var_hea_ansatz_param,\n",
        "        ):\n",
        "        r\"\"\"\n",
        "        Defines a Density Matrix Kernel Density Estimation quantum layer for learning with fixed qaff (Meaning of qaff?). (This function was originally named dmkde_mixed_variational_density_estimation_fixed_qaff)\n",
        "\n",
        "        Args:\n",
        "            U_dagger:\n",
        "            var_pure_state_param:\n",
        "\n",
        "        Returns:\n",
        "            The probabilities of :math:`|k\\rangle`, `|1\\rangle`, ..., `|k\\rangle` state for kernel density classification of the classes.\n",
        "        \"\"\"\n",
        "\n",
        "        ### indices pure state hea\n",
        "        index_iter_hea  = iter(np.arange(len(var_hea_ansatz_param)))\n",
        "\n",
        "        ### indices qeff\n",
        "        index_iter_qeff = iter(np.arange(self.qeff_weights.shape[1]))\n",
        "\n",
        "        ### indices classes, of ms\n",
        "        n_qubits_classes_qeff_temp = self.num_classes_qubits + self.n_qeff_qubits\n",
        "        index_qubit_states = _indices_qubits_classes(n_qubits_classes_qeff_temp, self.num_classes) # extract indices of the bit string of classes\n",
        "\n",
        "\n",
        "        # Instantiate a circuit with the calculated number of qubits.\n",
        "        self.circuit = tc.Circuit(self.n_total_qubits_temp)\n",
        "\n",
        "        def hea_ansatz(qc_param, num_qubits_param, num_layers_param):\n",
        "          # encoding\n",
        "          for i in range (0, num_qubits_param):\n",
        "            qc_param.ry(i, theta = var_hea_ansatz_param[next(index_iter_hea)])\n",
        "            qc_param.rz(i, theta = var_hea_ansatz_param[next(index_iter_hea)])\n",
        "          # layers\n",
        "          for j in range(num_layers_param):\n",
        "            for i in range (0, num_qubits_param-1):\n",
        "              qc_param.CNOT(i, i+1)\n",
        "\n",
        "            for i in range (0, num_qubits_param):\n",
        "              qc_param.ry(i, theta= var_hea_ansatz_param[next(index_iter_hea)])\n",
        "              qc_param.rz(i, theta= var_hea_ansatz_param[next(index_iter_hea)])\n",
        "\n",
        "        ## learning pure state with HEA\n",
        "        hea_ansatz(self.circuit, self.n_total_qubits_temp, self.num_layers_hea)\n",
        "\n",
        "        # Value to predict\n",
        "\n",
        "        x_sample_temp = tf.expand_dims(x_sample_param, axis=0)\n",
        "        phases_temp = (tf.cast(tf.sqrt(self.gamma), tf.float64)*tf.linalg.matmul(tf.cast(x_sample_temp, tf.float64), self.qeff_weights))[0]\n",
        "        init_qubit_qeff_temp = self.num_classes_qubits # qubit at which the qaff mapping starts it starts after the qubits of the classes\n",
        "\n",
        "        def circuit_base_rz_qeff_n(qc_param, num_qubits_param, target_qubit_param, init_qubit_param):\n",
        "          if num_qubits_param == 1:\n",
        "            qc_param.rz(init_qubit_param, theta = phases_temp[next(index_iter_qeff)] )\n",
        "          elif num_qubits_param == 2:\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[next(index_iter_qeff)])\n",
        "            qc_param.cnot(init_qubit_param, target_qubit_param + init_qubit_param)\n",
        "            qc_param.rz(target_qubit_param + init_qubit_param, theta = phases_temp[next(index_iter_qeff)])\n",
        "            return\n",
        "          else:\n",
        "            circuit_base_rz_qeff_n(qc_param, num_qubits_param-1, target_qubit_param, init_qubit_param)\n",
        "            qc_param.cnot(num_qubits_param-2 + init_qubit_param, target_qubit_param + init_qubit_param)\n",
        "            circuit_base_rz_qeff_n(qc_param, num_qubits_param-1, target_qubit_param, init_qubit_param)\n",
        "            target_qubit_param -= 1\n",
        "\n",
        "        # Applying the QEFF feature map\n",
        "\n",
        "        for i in reversed(range(1, self.n_qeff_qubits + 1)):\n",
        "          circuit_base_rz_qeff_n(self.circuit, i, i - 1, init_qubit_qeff_temp)\n",
        "\n",
        "        for i in range(init_qubit_qeff_temp, init_qubit_qeff_temp + self.n_qeff_qubits):\n",
        "          self.circuit.H(i)\n",
        "\n",
        "        # Trace out ancilla qubits, find probability of [000] state for density estimation\n",
        "        measurement_state = tc.quantum.reduced_density_matrix(\n",
        "                        self.circuit.state(),\n",
        "                        cut=[m for m in range(n_qubits_classes_qeff_temp, self.n_total_qubits_temp)])\n",
        "        measurements_results = tc.backend.real(tf.stack([measurement_state[index_qubit_states[i], index_qubit_states[i]] for i in range(self.num_classes)]))\n",
        "        if self.training_type == \"discriminative\":\n",
        "          measurements_results = measurements_results / tf.reduce_sum(measurements_results, axis = -1)\n",
        "        return measurements_results\n",
        "\n",
        "    def custom_categorical_crossentropy(self, y_true, y_pred):\n",
        "      ## code generated with the aid of chat gpt\n",
        "      \"\"\"\n",
        "      Compute the categorical cross-entropy loss with mean reduction.\n",
        "\n",
        "      Args:\n",
        "      y_true: Tensor of true labels, shape (batch_size, num_classes).\n",
        "      y_pred: Tensor of predicted probabilities, shape (batch_size, num_classes).\n",
        "\n",
        "      Returns:\n",
        "      Scalar tensor representing the mean loss over the batch.\n",
        "      \"\"\"\n",
        "      # Ensure predictions are clipped to avoid log(0)\n",
        "      epsilon_two = 1e-7  # small constant to avoid division by zero\n",
        "      y_pred = tf.clip_by_value(y_pred, epsilon_two, np.inf)  # clip values to avoid log(0) originaly 1.0 - epsilon\n",
        "\n",
        "      # Compute the categorical cross-entropy loss for each sample\n",
        "      loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
        "\n",
        "      if self.reduction == \"none\":\n",
        "        return loss\n",
        "      elif self.reduction == \"mean\":\n",
        "        # Compute the mean loss over the batch\n",
        "        mean_loss = tf.reduce_mean(loss)\n",
        "        return mean_loss\n",
        "      elif self.reduction == \"sum\":\n",
        "        # Compute the sum loss over the batch\n",
        "        sum_loss = tf.reduce_sum(loss)\n",
        "        return sum_loss\n",
        "      else:\n",
        "        return loss\n",
        "\n",
        "    def compile(\n",
        "            self,\n",
        "            optimizer=tf.keras.optimizers.Adam,\n",
        "            **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to compile the model.\n",
        "\n",
        "        Args:\n",
        "            optimizer:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "        self.model.compile(\n",
        "            loss = self.custom_categorical_crossentropy,\n",
        "            optimizer=optimizer(self.learning_rate),\n",
        "            metrics=[\"accuracy\"],\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "    def fit(self, x_train, y_train, batch_size=16, epochs = 30, **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to fit (train) the model using the ad-hoc dataset.\n",
        "\n",
        "        Args:\n",
        "            x_train:\n",
        "            y_train:\n",
        "            batch_size:\n",
        "            epochs:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model.fit(x_train, y_train, batch_size = self.batch_size, epochs = epochs, **kwargs)\n",
        "\n",
        "    def predict(self, x_test):\n",
        "      r\"\"\"\n",
        "      Method to make predictions with the trained model.\n",
        "\n",
        "      Args:\n",
        "          x_test:\n",
        "\n",
        "      Returns:\n",
        "          The predictions of the conditional density estimation of the input data.\n",
        "      \"\"\"\n",
        "      return (tf.experimental.numpy.power((self.gamma/(pi)), self.dim_lenet_out/2.)*\\\n",
        "          self.model.predict(x_test)).numpy()\n",
        "\n",
        "    def extract_lenet_features(self, x_test):\n",
        "      r\"\"\"\n",
        "      Method to extract the features of the Lenet.\n",
        "\n",
        "      Args:\n",
        "          x_test:\n",
        "\n",
        "      Returns:\n",
        "          Features of the Lenet.\n",
        "      \"\"\"\n",
        "      extract = Model(self.model.inputs, self.model.layers[-2].output)\n",
        "      new_model = Sequential()\n",
        "      new_model.add(extract)\n",
        "      return new_model.predict(x_test)\n",
        "\n",
        "    def freeze_lenet(self):\n",
        "      r\"\"\"\n",
        "      Method to frezze the layers of the Lenet.\n",
        "\n",
        "      Args:\n",
        "          self:\n",
        "\n",
        "      Returns:\n",
        "          None.\n",
        "      \"\"\"\n",
        "      for layer in self.model.layers[:-1]:\n",
        "          layer.trainable = False\n",
        "\n",
        "    def set_training_type(self, new_training_type):\n",
        "      r\"\"\"\n",
        "      Method to change the training type of the method during training.\n",
        "\n",
        "      Args:\n",
        "          new_training_strategy:\n",
        "\n",
        "      Returns:\n",
        "          None.\n",
        "      \"\"\"\n",
        "      self.training_type = new_training_type"
      ],
      "metadata": {
        "id": "XZik7fN8AxsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsdKFyKpAxsP"
      },
      "outputs": [],
      "source": [
        "## training the quantum circuit\n",
        "# Define a LeNet CNN feature extraction model\n",
        "input_shape = X_train.shape[1:]\n",
        "INPUT_DIM = input_shape[0]\n",
        "NUM_QUBITS_FFS = 4 ## originally N_QEFFS = 16\n",
        "NUM_CLASSES = 10\n",
        "NUM_CLASSES_QUBITS = 4\n",
        "DIM_LENET_OUT = 30 # originally 16\n",
        "GAMMA = 2**(-2) ## originally 2**(0)\n",
        "EPOCHS = 5\n",
        "N_TRAINING_DATA = X_train.shape[0]\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 0.0005 ## originally 0.0005\n",
        "RANDOM_STATE_QEFF = 123\n",
        "NUM_ANCILLA_QUBITS = 1\n",
        "NUM_TOTAL_QUBITS = NUM_QUBITS_FFS + NUM_ANCILLA_QUBITS + NUM_CLASSES_QUBITS\n",
        "NUM_LAYERS_HEA = int(np.round(((2**NUM_TOTAL_QUBITS-1)/NUM_TOTAL_QUBITS)-1))\n",
        "TRAINING_TYPE = \"generative\"\n",
        "REDUCTION = \"none\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "outputId": "bb350a35-c8e8-4c75-ef2c-61ba8723d932",
        "id": "Kj2lGGTAAxsP"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │             \u001b[38;5;34m520\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_2                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │          \u001b[38;5;34m25,050\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_3                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2450\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)                  │         \u001b[38;5;34m205,884\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │           \u001b[38;5;34m2,550\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ quantum_layer_1 (\u001b[38;5;33mQuantumLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,026\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_2                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,050</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_3                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2450</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">205,884</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ quantum_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">QuantumLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,030\u001b[0m (922.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,030</span> (922.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,030\u001b[0m (922.09 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,030</span> (922.09 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1361s\u001b[0m 232ms/step - accuracy: 0.7808 - loss: 0.9387\n",
            "Epoch 2/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m855s\u001b[0m 228ms/step - accuracy: 0.9879 - loss: 0.0845\n",
            "Epoch 3/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m869s\u001b[0m 230ms/step - accuracy: 0.9919 - loss: 0.0504\n",
            "Epoch 4/5\n",
            "\u001b[1m 744/3750\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13:22\u001b[0m 267ms/step - accuracy: 0.9948 - loss: 0.0307"
          ]
        }
      ],
      "source": [
        "## this code creates a discriminative model\n",
        "vqkdc_hea = VQKDC_MIXED_QEFF_HEA_LENET(n_qeff_qubits = NUM_QUBITS_FFS, n_ancilla_qubits =  NUM_ANCILLA_QUBITS, num_classes_qubits = NUM_CLASSES_QUBITS, num_classes_param = NUM_CLASSES, dim_lenet_out_param = DIM_LENET_OUT, input_dim_param = INPUT_DIM, gamma=GAMMA, n_training_data = N_TRAINING_DATA,  reduction = REDUCTION, training_type = TRAINING_TYPE, num_layers_hea = NUM_LAYERS_HEA, batch_size = BATCH_SIZE, learning_rate = LEARNING_RATE, random_state = RANDOM_STATE_QEFF, auto_compile = False)\n",
        "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
        "vqkdc_hea.model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "vqkdc_hea.fit(X_train, y_train_oh, epochs = EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this code frezzes the weights of the Le net layer, and then sets the model to be trained in a generative way\n",
        "for layer in vqkdc_hea.model.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "vqkdc_hea.compile()\n",
        "vqkdc_hea.fit(X_train, y_train_oh, epochs = EPOCHS)"
      ],
      "metadata": {
        "id": "ehkCsI6-AxsP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "24c41c51-e0b7-4c18-8587-c71aaa02fd71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m773s\u001b[0m 178ms/step - accuracy: 0.9843 - loss: 2.7037\n",
            "Epoch 2/5\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m679s\u001b[0m 178ms/step - accuracy: 0.9878 - loss: 2.3425\n",
            "Epoch 3/5\n",
            "\u001b[1m 431/3750\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:39\u001b[0m 175ms/step - accuracy: 0.9877 - loss: 2.3361"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e57e82caadb8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvqkdc_hea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvqkdc_hea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_oh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-58edbf3d5413>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, batch_size, epochs, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \"\"\"\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = vqkdc_hea.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test, np.argmax(y_pred, axis=1))"
      ],
      "metadata": {
        "id": "h43owVQJAxsQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0ce2414-2e9c-4fb7-807b-e9d8c84dcace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m628s\u001b[0m 1s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9864"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline model: Mixed QMC variational, ZZFM, with Le-Net Conv layer with HEA, Discriminative then generative learning, additional linear layer from dim of latent space to dim 4."
      ],
      "metadata": {
        "id": "iYOVeLucwDnX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWBZNC44wDnX"
      },
      "source": [
        "The number of parameters of the Hardware efficient ansatz is given by,\n",
        "\n",
        "\n",
        "```\n",
        "HEA_size = n_qubits * (num_layers_hea + 1) * 2\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Quantum variational KDC with QEFF\n",
        "\n",
        "import tensorcircuit as tc\n",
        "from tensorcircuit import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import math as m\n",
        "from scipy.stats import entropy, spearmanr\n",
        "\n",
        "tc.set_backend(\"tensorflow\")\n",
        "tc.set_dtype(\"complex128\")\n",
        "\n",
        "pi = tf.constant(m.pi)\n",
        "\n",
        "class VQKDC_MIXED_ZZFM_HEA_LENET:\n",
        "    r\"\"\"\n",
        "    Defines the ready-to-use Quantum measurement classification (QMC) model implemented\n",
        "    in TensorCircuit using the TensorFlow/Keras API. Any additional argument in the methods has to be Keras-compliant.\n",
        "\n",
        "    Args:\n",
        "        auto_compile: A boolean to autocompile the model using default settings. (Default True).\n",
        "        var_pure_state_size:\n",
        "        gamma:\n",
        "\n",
        "    Returns:\n",
        "        An instantiated model ready to train with ad-hoc data.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, n_qeff_qubits, n_ancilla_qubits, num_classes_qubits, num_classes_param, dim_lenet_out_param,  input_dim_param, gamma, n_training_data, num_zzfm_layers, reduction = \"none\", training_type = \"generative\", num_layers_hea = 3, batch_size = 16, learning_rate = 0.0005, auto_compile=True):\n",
        "\n",
        "        self.circuit = None\n",
        "        self.gamma = gamma\n",
        "        self.num_layers_hea = num_layers_hea\n",
        "        self.num_classes = num_classes_param\n",
        "        self.num_classes_qubits = num_classes_qubits\n",
        "        self.n_zzfm_qubits = n_qeff_qubits\n",
        "        self.n_ancilla_qubits = n_ancilla_qubits\n",
        "        self.n_total_qubits_temp = self.num_classes_qubits + self.n_zzfm_qubits + self.n_ancilla_qubits\n",
        "        self.n_training_data = n_training_data\n",
        "        self.dim_lenet_out = dim_lenet_out_param\n",
        "        self.input_dim = input_dim_param\n",
        "        self.num_zzfm_layers = num_zzfm_layers\n",
        "        self.var_hea_ansatz_size = int(self.n_total_qubits_temp*(self.num_layers_hea+1)*2)\n",
        "        self.reduction  = reduction\n",
        "        self.training_type = training_type\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        layer = keras.QuantumLayer(\n",
        "            partial(self.layer),\n",
        "            [(self.var_hea_ansatz_size,)]\n",
        "            )\n",
        "\n",
        "        ## build the Let-net model\n",
        "        #self.model = Sequential() ## keep for old code\n",
        "        self.model = Sequential() ## new code\n",
        "        self.model.add(tf.keras.layers.InputLayer(input_shape=(self.input_dim, self.input_dim, 1))) ## new code\n",
        "        #self.model.add(tf.keras.layers.Conv2D(filters=20, kernel_size=(5, 5), padding=\"same\", activation='relu', input_shape=(self.input_dim, self.input_dim, 1))) # keep for old code\n",
        "        self.model.add(tf.keras.layers.Conv2D(filters=20, kernel_size=(5, 5), padding=\"same\", activation='relu')) ## new code\n",
        "        self.model.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2))\n",
        "        self.model.add(tf.keras.layers.Conv2D(filters=50, kernel_size=(5, 5), padding=\"same\", activation='relu'))\n",
        "        self.model.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2))\n",
        "        self.model.add(tf.keras.layers.Flatten())\n",
        "        self.model.add(tf.keras.layers.Dense(units=84, activation='relu'))\n",
        "        self.model.add(tf.keras.layers.Dense(units=self.dim_lenet_out, activation = None)) # original \"softmax\"\n",
        "        self.model.add(tf.keras.layers.Dense(units=self.n_zzfm_qubits, activation = None))  ## we add this additional layer compared to normal models\n",
        "\n",
        "        # add the quantum layer\n",
        "\n",
        "        self.model.add(layer)\n",
        "        print(self.model.summary())\n",
        "\n",
        "        if auto_compile:\n",
        "            self.compile()\n",
        "\n",
        "    def layer(\n",
        "            self,\n",
        "            x_sample_param,\n",
        "            var_hea_ansatz_param,\n",
        "        ):\n",
        "        r\"\"\"\n",
        "        Defines a Density Matrix Kernel Density Estimation quantum layer for learning with fixed qaff (Meaning of qaff?). (This function was originally named dmkde_mixed_variational_density_estimation_fixed_qaff)\n",
        "\n",
        "        Args:\n",
        "            U_dagger:\n",
        "            var_pure_state_param:\n",
        "\n",
        "        Returns:\n",
        "            The probabilities of :math:`|k\\rangle`, `|1\\rangle`, ..., `|k\\rangle` state for kernel density classification of the classes.\n",
        "        \"\"\"\n",
        "\n",
        "        ### indices pure state hea\n",
        "        index_iter_hea  = iter(np.arange(len(var_hea_ansatz_param)))\n",
        "\n",
        "        ### indices classes, of ms\n",
        "        n_qubits_classes_zzfm_temp = self.num_classes_qubits + self.n_zzfm_qubits\n",
        "        index_qubit_states = _indices_qubits_classes(n_qubits_classes_zzfm_temp, self.num_classes) # extract indices of the bit string of classes\n",
        "\n",
        "        # Instantiate a circuit with the calculated number of qubits.\n",
        "        self.circuit = tc.Circuit(self.n_total_qubits_temp)\n",
        "\n",
        "        def hea_ansatz(qc_param, num_qubits_param, num_layers_param):\n",
        "          # encoding\n",
        "          for i in range (0, num_qubits_param):\n",
        "            qc_param.ry(i, theta = var_hea_ansatz_param[next(index_iter_hea)])\n",
        "            qc_param.rz(i, theta = var_hea_ansatz_param[next(index_iter_hea)])\n",
        "          # layers\n",
        "          for j in range(num_layers_param):\n",
        "            for i in range (0, num_qubits_param-1):\n",
        "              qc_param.CNOT(i, i+1)\n",
        "\n",
        "            for i in range (0, num_qubits_param):\n",
        "              qc_param.ry(i, theta= var_hea_ansatz_param[next(index_iter_hea)])\n",
        "              qc_param.rz(i, theta= var_hea_ansatz_param[next(index_iter_hea)])\n",
        "\n",
        "        ## learning pure state with HEA\n",
        "        hea_ansatz(self.circuit, self.n_total_qubits_temp, self.num_layers_hea)\n",
        "\n",
        "        # Value to predict zzfm\n",
        "        x_sample_temp = tf.expand_dims(x_sample_param, axis=0)\n",
        "        init_qubit_qeff_temp = self.num_classes_qubits # qubit at which the qaff mapping starts it starts after the qubits of the classes\n",
        "\n",
        "        for i in range(self.num_zzfm_layers):\n",
        "          for k in reversed(range(self.n_zzfm_qubits)):\n",
        "            for j in reversed(range(0, k)):\n",
        "              self.circuit.cnot(init_qubit_qeff_temp + j, init_qubit_qeff_temp + k)\n",
        "              self.circuit.rz(init_qubit_qeff_temp + k, theta = 2*(math.pi-x_sample_temp[0][j])*(math.pi-x_sample_temp[0][k]))\n",
        "              self.circuit.cnot(init_qubit_qeff_temp + j, init_qubit_qeff_temp + k)\n",
        "\n",
        "          for l in range(self.n_zzfm_qubits):\n",
        "            self.circuit.rz(init_qubit_qeff_temp + l, theta = 2*(x_sample_temp[0][l]))\n",
        "\n",
        "          for m in range(init_qubit_qeff_temp, init_qubit_qeff_temp + self.n_zzfm_qubits):\n",
        "            self.circuit.H(m)\n",
        "\n",
        "        # Trace out ancilla qubits, find probability of [000] state for density estimation\n",
        "        measurement_state = tc.quantum.reduced_density_matrix(\n",
        "                        self.circuit.state(),\n",
        "                        cut=[m for m in range(n_qubits_classes_zzfm_temp, self.n_total_qubits_temp)])\n",
        "        measurements_results = tc.backend.real(tf.stack([measurement_state[index_qubit_states[i], index_qubit_states[i]] for i in range(self.num_classes)]))\n",
        "        if self.training_type == \"discriminative\":\n",
        "          measurements_results = measurements_results / tf.reduce_sum(measurements_results, axis = -1)\n",
        "        return measurements_results\n",
        "\n",
        "    def custom_categorical_crossentropy(self, y_true, y_pred):\n",
        "      ## code generated with the aid of chat gpt\n",
        "      \"\"\"\n",
        "      Compute the categorical cross-entropy loss with mean reduction.\n",
        "\n",
        "      Args:\n",
        "      y_true: Tensor of true labels, shape (batch_size, num_classes).\n",
        "      y_pred: Tensor of predicted probabilities, shape (batch_size, num_classes).\n",
        "\n",
        "      Returns:\n",
        "      Scalar tensor representing the mean loss over the batch.\n",
        "      \"\"\"\n",
        "      # Ensure predictions are clipped to avoid log(0)\n",
        "      epsilon_two = 1e-7  # small constant to avoid division by zero\n",
        "      y_pred = tf.clip_by_value(y_pred, epsilon_two, np.inf)  # clip values to avoid log(0) originaly 1.0 - epsilon\n",
        "\n",
        "      # Compute the categorical cross-entropy loss for each sample\n",
        "      loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
        "\n",
        "      if self.reduction == \"none\":\n",
        "        return loss\n",
        "      elif self.reduction == \"mean\":\n",
        "        # Compute the mean loss over the batch\n",
        "        mean_loss = tf.reduce_mean(loss)\n",
        "        return mean_loss\n",
        "      elif self.reduction == \"sum\":\n",
        "        # Compute the sum loss over the batch\n",
        "        sum_loss = tf.reduce_sum(loss)\n",
        "        return sum_loss\n",
        "      else:\n",
        "        return loss\n",
        "\n",
        "    def compile(\n",
        "            self,\n",
        "            optimizer=tf.keras.optimizers.Adam,\n",
        "            **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to compile the model.\n",
        "\n",
        "        Args:\n",
        "            optimizer:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "        self.model.compile(\n",
        "            loss = self.custom_categorical_crossentropy,\n",
        "            optimizer=optimizer(self.learning_rate),\n",
        "            metrics=[\"accuracy\"],\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "    def fit(self, x_train, y_train, batch_size=16, epochs = 30, **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to fit (train) the model using the ad-hoc dataset.\n",
        "\n",
        "        Args:\n",
        "            x_train:\n",
        "            y_train:\n",
        "            batch_size:\n",
        "            epochs:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model.fit(x_train, y_train, batch_size = self.batch_size, epochs = epochs, **kwargs)\n",
        "\n",
        "    def predict(self, x_test):\n",
        "      r\"\"\"\n",
        "      Method to make predictions with the trained model.\n",
        "\n",
        "      Args:\n",
        "          x_test:\n",
        "\n",
        "      Returns:\n",
        "          The predictions of the conditional density estimation of the input data.\n",
        "      \"\"\"\n",
        "      return (tf.experimental.numpy.power((self.gamma/(pi)), self.dim_lenet_out/2.)*\\\n",
        "          self.model.predict(x_test)).numpy()\n",
        "\n",
        "    def extract_lenet_features(self, x_test):\n",
        "      r\"\"\"\n",
        "      Method to extract the features of the Lenet.\n",
        "\n",
        "      Args:\n",
        "          x_test:\n",
        "\n",
        "      Returns:\n",
        "          Features of the Lenet.\n",
        "      \"\"\"\n",
        "      extract = Model(self.model.inputs, self.model.layers[-2].output)\n",
        "      new_model = Sequential()\n",
        "      new_model.add(extract)\n",
        "      return new_model.predict(x_test)\n",
        "\n",
        "    def freeze_lenet(self):\n",
        "      r\"\"\"\n",
        "      Method to frezze the layers of the Lenet.\n",
        "\n",
        "      Args:\n",
        "          self:\n",
        "\n",
        "      Returns:\n",
        "          None.\n",
        "      \"\"\"\n",
        "      for layer in self.model.layers[:-1]:\n",
        "          layer.trainable = False\n",
        "\n",
        "    def set_training_type(self, new_training_type):\n",
        "      r\"\"\"\n",
        "      Method to change the training type of the method during training.\n",
        "\n",
        "      Args:\n",
        "          new_training_strategy:\n",
        "\n",
        "      Returns:\n",
        "          None.\n",
        "      \"\"\"\n",
        "      self.training_type = new_training_type"
      ],
      "metadata": {
        "id": "DIsKQbTtwDnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VQKDC_MIXED_ZZFM_HEA:\n",
        "    r\"\"\"\n",
        "    Defines the ready-to-use Quantum measurement classification (QMC) model implemented\n",
        "    in TensorCircuit using the TensorFlow/Keras API. Any additional argument in the methods has to be Keras-compliant.\n",
        "\n",
        "    Args:\n",
        "        auto_compile: A boolean to autocompile the model using default settings. (Default True).\n",
        "        var_pure_state_size:\n",
        "        gamma:\n",
        "\n",
        "    Returns:\n",
        "        An instantiated model ready to train with ad-hoc data.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, dim_x_param, n_zzfm_qubits, n_ancilla_qubits, num_classes_qubits, num_classes_param, n_training_data, num_zzfm_layers, reduction = \"none\", training_type = \"generative\", num_layers_hea = 3, batch_size = 16, learning_rate = 0.0005, auto_compile=True):\n",
        "\n",
        "        self.circuit = None\n",
        "        self.dim_x = dim_x_param\n",
        "        self.num_layers_hea = num_layers_hea\n",
        "        self.num_classes = num_classes_param\n",
        "        self.num_classes_qubits = num_classes_qubits\n",
        "        self.n_zzfm_qubits = n_zzfm_qubits\n",
        "        self.n_ancilla_qubits = n_ancilla_qubits\n",
        "        self.n_total_qubits_temp = self.num_classes_qubits + self.n_zzfm_qubits + self.n_ancilla_qubits\n",
        "        self.n_training_data = n_training_data\n",
        "        self.num_zzfm_layers = num_zzfm_layers\n",
        "        self.var_hea_ansatz_size = int(self.n_total_qubits_temp*(self.num_layers_hea+1)*2)\n",
        "        self.reduction  = reduction\n",
        "        self.training_type = training_type\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        layer = keras.QuantumLayer(\n",
        "            partial(self.layer),\n",
        "            [(self.var_hea_ansatz_size,)]\n",
        "            )\n",
        "\n",
        "        self.model = tf.keras.Sequential([layer])\n",
        "\n",
        "        if auto_compile:\n",
        "            self.compile()\n",
        "\n",
        "    def layer(\n",
        "            self,\n",
        "            x_sample_param,\n",
        "            var_hea_ansatz_param,\n",
        "        ):\n",
        "        r\"\"\"\n",
        "        Defines a Density Matrix Kernel Density Estimation quantum layer for learning with fixed qaff (Meaning of qaff?). (This function was originally named dmkde_mixed_variational_density_estimation_fixed_qaff)\n",
        "\n",
        "        Args:\n",
        "            U_dagger:\n",
        "            var_pure_state_param:\n",
        "\n",
        "        Returns:\n",
        "            The probabilities of :math:`|k\\rangle`, `|1\\rangle`, ..., `|k\\rangle` state for kernel density classification of the classes.\n",
        "        \"\"\"\n",
        "\n",
        "        ### indices pure state hea\n",
        "        index_iter_hea  = iter(np.arange(len(var_hea_ansatz_param)))\n",
        "\n",
        "        ### indices classes, of ms\n",
        "        n_qubits_classes_zzfm_temp = self.num_classes_qubits + self.n_zzfm_qubits\n",
        "        index_qubit_states = _indices_qubits_classes(n_qubits_classes_zzfm_temp, self.num_classes) # extract indices of the bit string of classes\n",
        "\n",
        "\n",
        "        # Instantiate a circuit with the calculated number of qubits.\n",
        "        self.circuit = tc.Circuit(self.n_total_qubits_temp)\n",
        "\n",
        "        def hea_ansatz(qc_param, num_qubits_param, num_layers_param):\n",
        "          # encoding\n",
        "          for i in range (0, num_qubits_param):\n",
        "            qc_param.ry(i, theta = var_hea_ansatz_param[next(index_iter_hea)])\n",
        "            qc_param.rz(i, theta = var_hea_ansatz_param[next(index_iter_hea)])\n",
        "          # layers\n",
        "          for j in range(num_layers_param):\n",
        "            for i in range (0, num_qubits_param-1):\n",
        "              qc_param.CNOT(i, i+1)\n",
        "\n",
        "            for i in range (0, num_qubits_param):\n",
        "              qc_param.ry(i, theta= var_hea_ansatz_param[next(index_iter_hea)])\n",
        "              qc_param.rz(i, theta= var_hea_ansatz_param[next(index_iter_hea)])\n",
        "\n",
        "        ## learning pure state with HEA\n",
        "        hea_ansatz(self.circuit, self.n_total_qubits_temp, self.num_layers_hea)\n",
        "\n",
        "        # Value to predict zzfm\n",
        "        x_sample_temp = tf.expand_dims(x_sample_param, axis=0)\n",
        "        init_qubit_qeff_temp = self.num_classes_qubits # qubit at which the qaff mapping starts it starts after the qubits of the classes\n",
        "\n",
        "        for i in range(self.num_zzfm_layers):\n",
        "          for k in reversed(range(self.n_zzfm_qubits)):\n",
        "            for j in reversed(range(0, k)):\n",
        "              self.circuit.cnot(init_qubit_qeff_temp + j, init_qubit_qeff_temp + k)\n",
        "              self.circuit.rz(init_qubit_qeff_temp + k, theta = 2*(math.pi-x_sample_temp[0][j])*(math.pi-x_sample_temp[0][k]))\n",
        "              self.circuit.cnot(init_qubit_qeff_temp + j, init_qubit_qeff_temp + k)\n",
        "\n",
        "          for l in range(self.n_zzfm_qubits):\n",
        "            self.circuit.rz(init_qubit_qeff_temp + l, theta = 2*(x_sample_temp[0][l]))\n",
        "\n",
        "          for m in range(init_qubit_qeff_temp, init_qubit_qeff_temp + self.n_zzfm_qubits):\n",
        "            self.circuit.H(m)\n",
        "\n",
        "        # Trace out ancilla qubits, find probability of [000] state for density estimation\n",
        "        measurement_state = tc.quantum.reduced_density_matrix(\n",
        "                        self.circuit.state(),\n",
        "                        cut=[m for m in range(n_qubits_classes_zzfm_temp, self.n_total_qubits_temp)])\n",
        "        measurements_results = tc.backend.real(tf.stack([measurement_state[index_qubit_states[i], index_qubit_states[i]] for i in range(self.num_classes)]))\n",
        "        if self.training_type == \"discriminative\":\n",
        "          measurements_results = measurements_results / tf.reduce_sum(measurements_results, axis = -1)\n",
        "        return measurements_results\n",
        "\n",
        "    def custom_categorical_crossentropy(self, y_true, y_pred):\n",
        "      ## code generated with the aid of chat gpt\n",
        "      \"\"\"\n",
        "      Compute the categorical cross-entropy loss with mean reduction.\n",
        "\n",
        "      Args:\n",
        "      y_true: Tensor of true labels, shape (batch_size, num_classes).\n",
        "      y_pred: Tensor of predicted probabilities, shape (batch_size, num_classes).\n",
        "\n",
        "      Returns:\n",
        "      Scalar tensor representing the mean loss over the batch.\n",
        "      \"\"\"\n",
        "      # Ensure predictions are clipped to avoid log(0)\n",
        "      epsilon_two = 1e-7  # small constant to avoid division by zero\n",
        "      y_pred = tf.clip_by_value(y_pred, epsilon_two, np.inf)  # clip values to avoid log(0) originaly 1.0 - epsilon\n",
        "\n",
        "      # Compute the categorical cross-entropy loss for each sample\n",
        "      loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
        "\n",
        "      if self.reduction == \"none\":\n",
        "        return loss\n",
        "      elif self.reduction == \"mean\":\n",
        "        # Compute the mean loss over the batch\n",
        "        mean_loss = tf.reduce_mean(loss)\n",
        "        return mean_loss\n",
        "      elif self.reduction == \"sum\":\n",
        "        # Compute the sum loss over the batch\n",
        "        sum_loss = tf.reduce_sum(loss)\n",
        "        return sum_loss\n",
        "      else:\n",
        "        return loss\n",
        "\n",
        "    def compile(\n",
        "            self,\n",
        "            optimizer=tf.keras.optimizers.Adam,\n",
        "            **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to compile the model.\n",
        "\n",
        "        Args:\n",
        "            optimizer:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "        self.model.compile(\n",
        "            loss = self.custom_categorical_crossentropy,\n",
        "            optimizer=optimizer(self.learning_rate),\n",
        "            metrics=[\"accuracy\"],\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "    def fit(self, x_train, y_train, batch_size=16, epochs = 30, **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to fit (train) the model using the ad-hoc dataset.\n",
        "\n",
        "        Args:\n",
        "            x_train:\n",
        "            y_train:\n",
        "            batch_size:\n",
        "            epochs:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model.fit(x_train, y_train, batch_size = self.batch_size, epochs = epochs, **kwargs)\n",
        "\n",
        "    def predict(self, x_test):\n",
        "      r\"\"\"\n",
        "      Method to make predictions with the trained model.\n",
        "\n",
        "      Args:\n",
        "          x_test:\n",
        "\n",
        "      Returns:\n",
        "          The predictions of the conditional density estimation of the input data.\n",
        "      \"\"\"\n",
        "      return self.model.predict(x_test)"
      ],
      "metadata": {
        "id": "Dm_Y6SViMD-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNhQWx_YwDnY"
      },
      "outputs": [],
      "source": [
        "## training the quantum circuit\n",
        "# Define a LeNet CNN feature extraction model\n",
        "input_shape = X_train.shape[1:]\n",
        "INPUT_DIM = input_shape[0]\n",
        "NUM_QUBITS_FFS = 4 ## originally N_QEFFS = 16\n",
        "NUM_CLASSES = 10\n",
        "NUM_CLASSES_QUBITS = 4\n",
        "DIM_LENET_OUT = 30 # originally 16\n",
        "GAMMA = 2**(-2) ## originally 2**(0)\n",
        "EPOCHS = 4\n",
        "N_TRAINING_DATA = X_train.shape[0]\n",
        "BATCH_SIZE = 16\n",
        "NUM_ZZFM_LAYERS = 2 ## set 2 for final experiments\n",
        "LEARNING_RATE = 0.0005 ## originally 0.0005\n",
        "RANDOM_STATE_QEFF = 123\n",
        "NUM_ANCILLA_QUBITS = 1\n",
        "NUM_TOTAL_QUBITS = NUM_QUBITS_FFS + NUM_ANCILLA_QUBITS + NUM_CLASSES_QUBITS\n",
        "NUM_LAYERS_HEA = int(np.round(((2**NUM_TOTAL_QUBITS-1)/NUM_TOTAL_QUBITS)-1))\n",
        "TRAINING_TYPE = \"generative\"\n",
        "REDUCTION = \"none\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "outputId": "7fed9ab4-be39-479a-d085-9d5ed564844a",
        "id": "d4pYMXNbwDnY"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │             \u001b[38;5;34m520\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d (\u001b[38;5;33mAveragePooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │          \u001b[38;5;34m25,050\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_1                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2450\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)                  │         \u001b[38;5;34m205,884\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │           \u001b[38;5;34m2,550\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m124\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ quantum_layer (\u001b[38;5;33mQuantumLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,026\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,050</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_1                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2450</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">205,884</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ quantum_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">QuantumLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,154\u001b[0m (922.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,154</span> (922.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,154\u001b[0m (922.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,154</span> (922.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/4\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1202s\u001b[0m 211ms/step - accuracy: 0.7149 - loss: 1.1444\n",
            "Epoch 2/4\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m790s\u001b[0m 211ms/step - accuracy: 0.9817 - loss: 0.1589\n",
            "Epoch 3/4\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m793s\u001b[0m 212ms/step - accuracy: 0.9873 - loss: 0.0982\n",
            "Epoch 4/4\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m802s\u001b[0m 212ms/step - accuracy: 0.9908 - loss: 0.0815\n"
          ]
        }
      ],
      "source": [
        "## this code creates a discriminative model\n",
        "vqkdc_zzfm_hea_lenet = VQKDC_MIXED_ZZFM_HEA_LENET(n_qeff_qubits = NUM_QUBITS_FFS, n_ancilla_qubits =  NUM_ANCILLA_QUBITS, num_classes_qubits = NUM_CLASSES_QUBITS, num_classes_param = NUM_CLASSES, dim_lenet_out_param = DIM_LENET_OUT, input_dim_param = INPUT_DIM, gamma=GAMMA, n_training_data = N_TRAINING_DATA, num_zzfm_layers = NUM_ZZFM_LAYERS, reduction = REDUCTION, training_type = TRAINING_TYPE, num_layers_hea = NUM_LAYERS_HEA, batch_size = BATCH_SIZE, learning_rate = LEARNING_RATE, auto_compile = False)\n",
        "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
        "vqkdc_zzfm_hea_lenet.model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "vqkdc_zzfm_hea_lenet.fit(X_train, y_train_oh, epochs = EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model only for feature extraction with intermediate sigmoid activation\n",
        "extract = tf.keras.Model(vqkdc_zzfm_hea_lenet.model.inputs, vqkdc_zzfm_hea_lenet.model.layers[-2].output)\n",
        "print(extract.summary())\n",
        "\n",
        "X_train_feats = extract.predict(X_train)\n",
        "X_test_feats = extract.predict(X_test)\n",
        "\n",
        "X_train_feats.shape, X_test_feats.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "1MsTZlFJyDHL",
        "outputId": "2e68541c-dc6a-45a4-b606-9b855d802d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │             \u001b[38;5;34m520\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d (\u001b[38;5;33mAveragePooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │          \u001b[38;5;34m25,050\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_1                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2450\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)                  │         \u001b[38;5;34m205,884\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │           \u001b[38;5;34m2,550\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m124\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,050</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_1                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2450</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">205,884</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m234,128\u001b[0m (914.56 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">234,128</span> (914.56 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m234,128\u001b[0m (914.56 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">234,128</span> (914.56 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 17ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 4), (10000, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#del extract\n",
        "del extract\n",
        "del vqkdc_zzfm_hea_lenet"
      ],
      "metadata": {
        "id": "6BwjFkyw7_vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "# Call garbage collector\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVJYyO6SCyU8",
        "outputId": "fabc5d01-d3fc-4f4d-e148-ceabdc3c94db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1013"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## training the VQKDC quantum circuit with features in a generative way\n",
        "vqkdc_zzfm_hea = VQKDC_MIXED_ZZFM_HEA(dim_x_param = NUM_QUBITS_FFS, n_zzfm_qubits = NUM_QUBITS_FFS, n_ancilla_qubits =  NUM_ANCILLA_QUBITS, num_classes_qubits = NUM_CLASSES_QUBITS, num_classes_param = NUM_CLASSES, n_training_data = N_TRAINING_DATA, num_zzfm_layers = NUM_ZZFM_LAYERS, reduction = REDUCTION, training_type = TRAINING_TYPE, num_layers_hea = NUM_LAYERS_HEA, batch_size = BATCH_SIZE, learning_rate = LEARNING_RATE)\n",
        "vqkdc_zzfm_hea.fit(X_train_feats, y_train_oh, epochs = EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi3PxhPvwDnY",
        "outputId": "99b06e24-6b55-4ce7-ca3f-d7553a92e522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1333s\u001b[0m 175ms/step - accuracy: 0.7137 - loss: 3.1419\n",
            "Epoch 2/4\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 174ms/step - accuracy: 0.9868 - loss: 2.3519\n",
            "Epoch 3/4\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m655s\u001b[0m 175ms/step - accuracy: 0.9877 - loss: 2.3406\n",
            "Epoch 4/4\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m685s\u001b[0m 176ms/step - accuracy: 0.9873 - loss: 2.3396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vqkdc_zzfm_hea.model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "gVyA6gbB6t05",
        "outputId": "ec506ccd-3b43-4b13-e8ea-e3ca7b0903aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ quantum_layer_1 (\u001b[38;5;33mQuantumLayer\u001b[0m)       │ (\u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m10\u001b[0m)                    │           \u001b[38;5;34m1,026\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ quantum_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">QuantumLayer</span>)       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,080\u001b[0m (24.06 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,080</span> (24.06 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,026\u001b[0m (8.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> (8.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,054\u001b[0m (16.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,054</span> (16.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = vqkdc_zzfm_hea.predict(X_test_feats)\n",
        "\n",
        "accuracy_score(y_test, np.argmax(y_pred, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFGnW22KwDnY",
        "outputId": "a76525c0-2e4e-4903-cb86-ead97a6d4ec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m594s\u001b[0m 1s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9846"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_4Ui-bpIQuv",
        "outputId": "72705de2-7ed0-4ddc-8d7c-d520e990d51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Draft code"
      ],
      "metadata": {
        "id": "LsNHiTmnusSp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline model 2: Mixed QMC variational, ZZFM, with Le-Net Conv layer with HEA, Discriminative then generative learning, additional linear layer from dim of latent space to dim 4.\n",
        "\n",
        "This model works but break the RAM"
      ],
      "metadata": {
        "id": "Uk_lruFumoVw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F12mKkamoVx"
      },
      "source": [
        "The number of parameters of the Hardware efficient ansatz is given by,\n",
        "\n",
        "\n",
        "```\n",
        "HEA_size = n_qubits * (num_layers_hea + 1) * 2\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Quantum variational KDC with QEFF\n",
        "\n",
        "import tensorcircuit as tc\n",
        "from tensorcircuit import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "import math as m\n",
        "from scipy.stats import entropy, spearmanr\n",
        "\n",
        "tc.set_backend(\"tensorflow\")\n",
        "tc.set_dtype(\"complex128\")\n",
        "\n",
        "pi = tf.constant(m.pi)\n",
        "\n",
        "class VQKDC_MIXED_ZZFM_HEA_LENET:\n",
        "    r\"\"\"\n",
        "    Defines the ready-to-use Quantum measurement classification (QMC) model implemented\n",
        "    in TensorCircuit using the TensorFlow/Keras API. Any additional argument in the methods has to be Keras-compliant.\n",
        "\n",
        "    Args:\n",
        "        auto_compile: A boolean to autocompile the model using default settings. (Default True).\n",
        "        var_pure_state_size:\n",
        "        gamma:\n",
        "\n",
        "    Returns:\n",
        "        An instantiated model ready to train with ad-hoc data.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, n_qeff_qubits, n_ancilla_qubits, num_classes_qubits, num_classes_param, dim_lenet_out_param,  input_dim_param, gamma, n_training_data, num_zzfm_layers, reduction = \"none\", training_type = \"generative\", num_layers_hea = 3, batch_size = 16, learning_rate = 0.0005, auto_compile=True):\n",
        "\n",
        "        self.circuit = None\n",
        "        self.gamma = gamma\n",
        "        self.num_layers_hea = num_layers_hea\n",
        "        self.num_classes = num_classes_param\n",
        "        self.num_classes_qubits = num_classes_qubits\n",
        "        self.n_zzfm_qubits = n_qeff_qubits\n",
        "        self.n_ancilla_qubits = n_ancilla_qubits\n",
        "        self.n_total_qubits_temp = self.num_classes_qubits + self.n_zzfm_qubits + self.n_ancilla_qubits\n",
        "        self.n_training_data = n_training_data\n",
        "        self.dim_lenet_out = dim_lenet_out_param\n",
        "        self.input_dim = input_dim_param\n",
        "        self.num_zzfm_layers = num_zzfm_layers\n",
        "        self.var_hea_ansatz_size = int(self.n_total_qubits_temp*(self.num_layers_hea+1)*2)\n",
        "        self.reduction  = reduction\n",
        "        self.training_type = training_type\n",
        "        self.learning_rate = learning_rate\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        layer = keras.QuantumLayer(\n",
        "            partial(self.layer),\n",
        "            [(self.var_hea_ansatz_size,)]\n",
        "            )\n",
        "\n",
        "        ## build the Let-net model\n",
        "        self.model = Sequential() ## keep for old code\n",
        "        #self.model = Sequential() ## new code\n",
        "        #self.model.add(tf.keras.layers.InputLayer(input_shape=(self.input_dim, self.input_dim, 1))) ## new code\n",
        "        self.model.add(tf.keras.layers.Conv2D(filters=20, kernel_size=(5, 5), padding=\"same\", activation='relu', input_shape=(self.input_dim, self.input_dim, 1)))\n",
        "        self.model.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2))\n",
        "        self.model.add(tf.keras.layers.Conv2D(filters=50, kernel_size=(5, 5), padding=\"same\", activation='relu'))\n",
        "        self.model.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2))\n",
        "        self.model.add(tf.keras.layers.Flatten())\n",
        "        self.model.add(tf.keras.layers.Dense(units=84, activation='relu'))\n",
        "        self.model.add(tf.keras.layers.Dense(units=self.dim_lenet_out, activation = None)) # original \"softmax\"\n",
        "        self.model.add(tf.keras.layers.Dense(units=self.n_zzfm_qubits, activation = None))  ## we add this additional layer compared to normal models\n",
        "\n",
        "        # add the quantum layer\n",
        "\n",
        "        self.model.add(layer)\n",
        "        print(self.model.summary())\n",
        "\n",
        "        if auto_compile:\n",
        "            self.compile()\n",
        "\n",
        "    def layer(\n",
        "            self,\n",
        "            x_sample_param,\n",
        "            var_hea_ansatz_param,\n",
        "        ):\n",
        "        r\"\"\"\n",
        "        Defines a Density Matrix Kernel Density Estimation quantum layer for learning with fixed qaff (Meaning of qaff?). (This function was originally named dmkde_mixed_variational_density_estimation_fixed_qaff)\n",
        "\n",
        "        Args:\n",
        "            U_dagger:\n",
        "            var_pure_state_param:\n",
        "\n",
        "        Returns:\n",
        "            The probabilities of :math:`|k\\rangle`, `|1\\rangle`, ..., `|k\\rangle` state for kernel density classification of the classes.\n",
        "        \"\"\"\n",
        "\n",
        "        ### indices pure state hea\n",
        "        index_iter_hea  = iter(np.arange(len(var_hea_ansatz_param)))\n",
        "\n",
        "        ### indices classes, of ms\n",
        "        n_qubits_classes_zzfm_temp = self.num_classes_qubits + self.n_zzfm_qubits\n",
        "        index_qubit_states = _indices_qubits_classes(n_qubits_classes_zzfm_temp, self.num_classes) # extract indices of the bit string of classes\n",
        "\n",
        "        # Instantiate a circuit with the calculated number of qubits.\n",
        "        self.circuit = tc.Circuit(self.n_total_qubits_temp)\n",
        "\n",
        "        def hea_ansatz(qc_param, num_qubits_param, num_layers_param):\n",
        "          # encoding\n",
        "          for i in range (0, num_qubits_param):\n",
        "            qc_param.ry(i, theta = var_hea_ansatz_param[next(index_iter_hea)])\n",
        "            qc_param.rz(i, theta = var_hea_ansatz_param[next(index_iter_hea)])\n",
        "          # layers\n",
        "          for j in range(num_layers_param):\n",
        "            for i in range (0, num_qubits_param-1):\n",
        "              qc_param.CNOT(i, i+1)\n",
        "\n",
        "            for i in range (0, num_qubits_param):\n",
        "              qc_param.ry(i, theta= var_hea_ansatz_param[next(index_iter_hea)])\n",
        "              qc_param.rz(i, theta= var_hea_ansatz_param[next(index_iter_hea)])\n",
        "\n",
        "        ## learning pure state with HEA\n",
        "        hea_ansatz(self.circuit, self.n_total_qubits_temp, self.num_layers_hea)\n",
        "\n",
        "        # Value to predict zzfm\n",
        "        x_sample_temp = tf.expand_dims(x_sample_param, axis=0)\n",
        "        init_qubit_qeff_temp = self.num_classes_qubits # qubit at which the qaff mapping starts it starts after the qubits of the classes\n",
        "\n",
        "        for i in range(self.num_zzfm_layers):\n",
        "          for k in reversed(range(self.n_zzfm_qubits)):\n",
        "            for j in reversed(range(0, k)):\n",
        "              self.circuit.cnot(init_qubit_qeff_temp + j, init_qubit_qeff_temp + k)\n",
        "              self.circuit.rz(init_qubit_qeff_temp + k, theta = 2*(math.pi-x_sample_temp[0][j])*(math.pi-x_sample_temp[0][k]))\n",
        "              self.circuit.cnot(init_qubit_qeff_temp + j, init_qubit_qeff_temp + k)\n",
        "\n",
        "          for l in range(self.n_zzfm_qubits):\n",
        "            self.circuit.rz(init_qubit_qeff_temp + l, theta = 2*(x_sample_temp[0][l]))\n",
        "\n",
        "          for m in range(init_qubit_qeff_temp, init_qubit_qeff_temp + self.n_zzfm_qubits):\n",
        "            self.circuit.H(m)\n",
        "\n",
        "        # Trace out ancilla qubits, find probability of [000] state for density estimation\n",
        "        measurement_state = tc.quantum.reduced_density_matrix(\n",
        "                        self.circuit.state(),\n",
        "                        cut=[m for m in range(n_qubits_classes_zzfm_temp, self.n_total_qubits_temp)])\n",
        "        measurements_results = tc.backend.real(tf.stack([measurement_state[index_qubit_states[i], index_qubit_states[i]] for i in range(self.num_classes)]))\n",
        "        if self.training_type == \"discriminative\":\n",
        "          measurements_results = measurements_results / tf.reduce_sum(measurements_results, axis = -1)\n",
        "        return measurements_results\n",
        "\n",
        "    def custom_categorical_crossentropy(self, y_true, y_pred):\n",
        "      ## code generated with the aid of chat gpt\n",
        "      \"\"\"\n",
        "      Compute the categorical cross-entropy loss with mean reduction.\n",
        "\n",
        "      Args:\n",
        "      y_true: Tensor of true labels, shape (batch_size, num_classes).\n",
        "      y_pred: Tensor of predicted probabilities, shape (batch_size, num_classes).\n",
        "\n",
        "      Returns:\n",
        "      Scalar tensor representing the mean loss over the batch.\n",
        "      \"\"\"\n",
        "      # Ensure predictions are clipped to avoid log(0)\n",
        "      epsilon_two = 1e-7  # small constant to avoid division by zero\n",
        "      y_pred = tf.clip_by_value(y_pred, epsilon_two, np.inf)  # clip values to avoid log(0) originaly 1.0 - epsilon\n",
        "\n",
        "      # Compute the categorical cross-entropy loss for each sample\n",
        "      loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
        "\n",
        "      if self.reduction == \"none\":\n",
        "        return loss\n",
        "      elif self.reduction == \"mean\":\n",
        "        # Compute the mean loss over the batch\n",
        "        mean_loss = tf.reduce_mean(loss)\n",
        "        return mean_loss\n",
        "      elif self.reduction == \"sum\":\n",
        "        # Compute the sum loss over the batch\n",
        "        sum_loss = tf.reduce_sum(loss)\n",
        "        return sum_loss\n",
        "      else:\n",
        "        return loss\n",
        "\n",
        "    def compile(\n",
        "            self,\n",
        "            optimizer=tf.keras.optimizers.Adam,\n",
        "            **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to compile the model.\n",
        "\n",
        "        Args:\n",
        "            optimizer:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "        self.model.compile(\n",
        "            loss = self.custom_categorical_crossentropy,\n",
        "            optimizer=optimizer(self.learning_rate),\n",
        "            metrics=[\"accuracy\"],\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "    def fit(self, x_train, y_train, batch_size=16, epochs = 30, **kwargs):\n",
        "        r\"\"\"\n",
        "        Method to fit (train) the model using the ad-hoc dataset.\n",
        "\n",
        "        Args:\n",
        "            x_train:\n",
        "            y_train:\n",
        "            batch_size:\n",
        "            epochs:\n",
        "            **kwargs: Any additional argument.\n",
        "\n",
        "        Returns:\n",
        "            None.\n",
        "        \"\"\"\n",
        "\n",
        "        self.model.fit(x_train, y_train, batch_size = self.batch_size, epochs = epochs, **kwargs)\n",
        "\n",
        "    def predict(self, x_test):\n",
        "      r\"\"\"\n",
        "      Method to make predictions with the trained model.\n",
        "\n",
        "      Args:\n",
        "          x_test:\n",
        "\n",
        "      Returns:\n",
        "          The predictions of the conditional density estimation of the input data.\n",
        "      \"\"\"\n",
        "      return (tf.experimental.numpy.power((self.gamma/(pi)), self.dim_lenet_out/2.)*\\\n",
        "          self.model.predict(x_test)).numpy()\n",
        "\n",
        "    def extract_lenet_features(self, x_test):\n",
        "      r\"\"\"\n",
        "      Method to extract the features of the Lenet.\n",
        "\n",
        "      Args:\n",
        "          x_test:\n",
        "\n",
        "      Returns:\n",
        "          Features of the Lenet.\n",
        "      \"\"\"\n",
        "      extract = Model(self.model.inputs, self.model.layers[-2].output)\n",
        "      new_model = Sequential()\n",
        "      new_model.add(extract)\n",
        "      return new_model.predict(x_test)\n",
        "\n",
        "    def freeze_lenet(self):\n",
        "      r\"\"\"\n",
        "      Method to frezze the layers of the Lenet.\n",
        "\n",
        "      Args:\n",
        "          self:\n",
        "\n",
        "      Returns:\n",
        "          None.\n",
        "      \"\"\"\n",
        "      for layer in self.model.layers[:-1]:\n",
        "          layer.trainable = False\n",
        "\n",
        "    def set_training_type(self, new_training_type):\n",
        "      r\"\"\"\n",
        "      Method to change the training type of the method during training.\n",
        "\n",
        "      Args:\n",
        "          new_training_strategy:\n",
        "\n",
        "      Returns:\n",
        "          None.\n",
        "      \"\"\"\n",
        "      self.training_type = new_training_type"
      ],
      "metadata": {
        "id": "iKt1axSVmoVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIPADZocmoVy"
      },
      "outputs": [],
      "source": [
        "## training the quantum circuit\n",
        "# Define a LeNet CNN feature extraction model\n",
        "input_shape = X_train.shape[1:]\n",
        "INPUT_DIM = input_shape[0]\n",
        "NUM_QUBITS_FFS = 4 ## originally N_QEFFS = 16\n",
        "NUM_CLASSES = 10\n",
        "NUM_CLASSES_QUBITS = 4\n",
        "DIM_LENET_OUT = 30 # originally 16\n",
        "GAMMA = 2**(-2) ## originally 2**(0)\n",
        "EPOCHS = 4\n",
        "N_TRAINING_DATA = X_train.shape[0]\n",
        "BATCH_SIZE = 16\n",
        "NUM_ZZFM_LAYERS = 2 ## set 2 for final experiments\n",
        "LEARNING_RATE = 0.0005 ## originally 0.0005\n",
        "RANDOM_STATE_QEFF = 123\n",
        "NUM_ANCILLA_QUBITS = 1\n",
        "NUM_TOTAL_QUBITS = NUM_QUBITS_FFS + NUM_ANCILLA_QUBITS + NUM_CLASSES_QUBITS\n",
        "NUM_LAYERS_HEA = int(np.round(((2**NUM_TOTAL_QUBITS-1)/NUM_TOTAL_QUBITS)-1))\n",
        "TRAINING_TYPE = \"generative\"\n",
        "REDUCTION = \"none\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "outputId": "4cf7915a-7455-4633-a606-1059a7bebe94",
        "id": "Meh0HXQtmoVy"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │             \u001b[38;5;34m520\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d (\u001b[38;5;33mAveragePooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m20\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m50\u001b[0m)          │          \u001b[38;5;34m25,050\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_1                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m50\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2450\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)                  │         \u001b[38;5;34m205,884\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │           \u001b[38;5;34m2,550\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m124\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ quantum_layer (\u001b[38;5;33mQuantumLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,026\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">25,050</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_1                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2450</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">205,884</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ quantum_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">QuantumLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m235,154\u001b[0m (922.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,154</span> (922.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m235,154\u001b[0m (922.58 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">235,154</span> (922.58 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/4\n",
            "\u001b[1m 258/3750\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:13\u001b[0m 193ms/step - accuracy: 0.2316 - loss: 2.9940"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-4ddfcc7fcd5e>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvqkdc_zzfm_hea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvqkdc_zzfm_hea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_oh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-03b9897a0f40>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, batch_size, epochs, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \"\"\"\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "## this code creates a discriminative model\n",
        "vqkdc_zzfm_hea = VQKDC_MIXED_ZZFM_HEA_LENET(n_qeff_qubits = NUM_QUBITS_FFS, n_ancilla_qubits =  NUM_ANCILLA_QUBITS, num_classes_qubits = NUM_CLASSES_QUBITS, num_classes_param = NUM_CLASSES, dim_lenet_out_param = DIM_LENET_OUT, input_dim_param = INPUT_DIM, gamma=GAMMA, n_training_data = N_TRAINING_DATA, num_zzfm_layers = NUM_ZZFM_LAYERS, reduction = REDUCTION, training_type = TRAINING_TYPE, num_layers_hea = NUM_LAYERS_HEA, batch_size = BATCH_SIZE, learning_rate = LEARNING_RATE, auto_compile = False)\n",
        "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
        "vqkdc_zzfm_hea.model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "vqkdc_zzfm_hea.fit(X_train, y_train_oh, epochs = EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## training the quantum circuit\n",
        "vqkdc_zzfm_hea_generative = VQKDC_MIXED_ZZFM_HEA(dim_x_param = NUM_QUBITS_FFS, n_qeff_qubits = NUM_QUBITS_FFS, n_ancilla_qubits =  NUM_ANCILLA_QUBITS, num_classes_qubits = NUM_CLASSES_QUBITS, num_classes_param = NUM_CLASSES, n_training_data = N_TRAINING_DATA, num_zzfm_layers = NUM_ZZFM_LAYERS, reduction = REDUCTION, training_type = TRAINING_TYPE, num_layers_hea = NUM_LAYERS_HEA, batch_size = BATCH_SIZE, learning_rate = LEARNING_RATE)\n",
        "\n",
        "vqkdc_zzfm_hea_generative.fit(X_train_feats, y_train_oh, epochs = EPOCHS)"
      ],
      "metadata": {
        "id": "FdJ721G-MsBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this code frezzes the weights of the Le net layer, and then sets the model to be trained in a generative way\n",
        "for layer in vqkdc_zzfm_hea.model.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "vqkdc_zzfm_hea.compile()\n",
        "vqkdc_zzfm_hea.fit(X_train, y_train_oh, epochs = EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "ccd619cf-df3a-472f-fd89-b51a87ef7a69",
        "id": "CjTWy8bRmoVz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'vqkdc_zzfm_hea' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-03b43156ed42>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# this code frezzes the weights of the Le net layer, and then sets the model to be trained in a generative way\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvqkdc_zzfm_hea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvqkdc_zzfm_hea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvqkdc_zzfm_hea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_oh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vqkdc_zzfm_hea' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = vqkdc_zzfm_hea.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test, np.argmax(y_pred, axis=1))"
      ],
      "metadata": {
        "id": "11irQTzrmoVz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}